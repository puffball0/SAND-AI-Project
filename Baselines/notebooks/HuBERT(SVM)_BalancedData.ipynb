{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8feafcae16a45af95372be50c971234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0227c80f93941b8b2205b72bc75d380",
              "IPY_MODEL_a779eff5542e4932bdc304510f686044",
              "IPY_MODEL_71c8224a374542159ab1241425387697"
            ],
            "layout": "IPY_MODEL_0651e8acd9d546979095fdd80532efcb"
          }
        },
        "d0227c80f93941b8b2205b72bc75d380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34d1a8ee166946a4bcf76b8d303ba701",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9fc4e5fa6c854e26a295d9cf0f0c1d0b",
            "value": "‚Äá‚ÄáExtracting:‚Äá100%"
          }
        },
        "a779eff5542e4932bdc304510f686044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d1bf910fad64cf883655a2169aaf40a",
            "max": 219,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b03cdaa72f7f4fcb801d501306776a8a",
            "value": 219
          }
        },
        "71c8224a374542159ab1241425387697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d9b3b421f5d42bdab11d45685f55fb4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1a3259f392854767ba0b4ea466001772",
            "value": "‚Äá219/219‚Äá[03:30&lt;00:00,‚Äá‚Äá1.40it/s]"
          }
        },
        "0651e8acd9d546979095fdd80532efcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34d1a8ee166946a4bcf76b8d303ba701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc4e5fa6c854e26a295d9cf0f0c1d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d1bf910fad64cf883655a2169aaf40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03cdaa72f7f4fcb801d501306776a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d9b3b421f5d42bdab11d45685f55fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a3259f392854767ba0b4ea466001772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb935b33f82412eafa9221d5631da68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8b58c1a2a6f4f25807dba583d0d4108",
              "IPY_MODEL_d0edba10e0b24edc8013012391b67055",
              "IPY_MODEL_0e9f3cf7b7e44baeaab515df006aa4cc"
            ],
            "layout": "IPY_MODEL_9aefe307c78241f48405f24b062d9228"
          }
        },
        "e8b58c1a2a6f4f25807dba583d0d4108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf0b05da4e0475291354861a8e5a6cb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eb8ddba6565d4c34856e300cf19f1e4f",
            "value": "‚Äá‚ÄáExtracting:‚Äá100%"
          }
        },
        "d0edba10e0b24edc8013012391b67055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52609afa6f2c414babf54205720b6674",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0e397e7cff14730b6fda370dd03fe9b",
            "value": 53
          }
        },
        "0e9f3cf7b7e44baeaab515df006aa4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2a26a24dbb24085864982c57268126b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_48fd09cf9ae64c1bb347b5a0052c7b43",
            "value": "‚Äá53/53‚Äá[00:43&lt;00:00,‚Äá‚Äá1.03s/it]"
          }
        },
        "9aefe307c78241f48405f24b062d9228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf0b05da4e0475291354861a8e5a6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8ddba6565d4c34856e300cf19f1e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52609afa6f2c414babf54205720b6674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0e397e7cff14730b6fda370dd03fe9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2a26a24dbb24085864982c57268126b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48fd09cf9ae64c1bb347b5a0052c7b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sbGCOmie-fZ9",
        "outputId": "e5752477-2437-45ac-80e1-873ff622ead7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SAND CHALLENGE - HUBERT BASELINE (STATE-OF-THE-ART)\n",
            "================================================================================\n",
            "Mounted at /content/drive\n",
            "\n",
            "[1/7] Installing required packages...\n",
            "‚è± This will take 2-3 minutes...\n",
            "Found existing installation: transformers 4.57.1\n",
            "Uninstalling transformers-4.57.1:\n",
            "  Successfully uninstalled transformers-4.57.1\n",
            "Found existing installation: huggingface-hub 0.36.0\n",
            "Uninstalling huggingface-hub-0.36.0:\n",
            "  Successfully uninstalled huggingface-hub-0.36.0\n",
            "Found existing installation: tokenizers 0.22.1\n",
            "Uninstalling tokenizers-0.22.1:\n",
            "  Successfully uninstalled tokenizers-0.22.1\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: SETUP AND INSTALLATION (WITH AUTO-RESTART)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"SAND CHALLENGE - HUBERT BASELINE (STATE-OF-THE-ART)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Install required packages\n",
        "print(\"\\n[1/7] Installing required packages...\")\n",
        "print(\"‚è± This will take 2-3 minutes...\")\n",
        "\n",
        "# Uninstall conflicting packages first\n",
        "!pip uninstall -y transformers huggingface_hub tokenizers\n",
        "\n",
        "# Install fresh compatible versions\n",
        "!pip install transformers==4.40.0 -q\n",
        "!pip install torch torchaudio -q\n",
        "!pip install scikit-learn pandas numpy -q\n",
        "!pip install librosa soundfile -q\n",
        "!pip install optuna -q\n",
        "!pip install matplotlib seaborn -q\n",
        "!pip install imbalanced-learn -q  # ‚≠ê ADDED FOR SMOTE\n",
        "\n",
        "print(\"‚úÖ Installation complete!\")\n",
        "print(\"üîÑ Restarting runtime...\")\n",
        "\n",
        "# Automatic restart\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 2: IMPORTS (RUN AFTER RESTART)\n",
        "# ============================================================================\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "from transformers import (\n",
        "    HubertModel,\n",
        "    AutoFeatureExtractor\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    confusion_matrix, classification_report, cohen_kappa_score\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from tqdm.auto import tqdm\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Mount Drive again after restart\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"‚úÖ Using device: {device}\")\n",
        "\n",
        "# Set random seeds\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "B3OmqFLz-nE2",
        "outputId": "52a127e8-7772-4e5b-9fb4-4f19f42eb2d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Using device: cuda\n",
            "‚úÖ All imports successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 3: CONFIGURATION\n",
        "# ============================================================================\n",
        "class Config:\n",
        "    \"\"\"Configuration for HuBERT baseline\"\"\"\n",
        "\n",
        "    # Paths\n",
        "    BASE_PATH = '/content/drive/MyDrive/SAND_Project_Data'\n",
        "    TRAINING_PATH = os.path.join(BASE_PATH, 'training')\n",
        "    EXCEL_PATH = os.path.join(BASE_PATH, 'sand_task_1.xlsx')\n",
        "    OUTPUT_PATH = os.path.join(BASE_PATH, 'hubert_baseline_results')\n",
        "\n",
        "    # Sheet names\n",
        "    SHEET_TRAINING_BASELINE = 'Training Baseline - Task 1'\n",
        "    SHEET_VALIDATION_BASELINE = 'Validation Baseline - Task 1'\n",
        "\n",
        "    # Audio types\n",
        "    AUDIO_TYPES = ['phonationA', 'phonationE', 'phonationI', 'phonationO', 'phonationU',\n",
        "                   'rhythmKA', 'rhythmPA', 'rhythmTA']\n",
        "\n",
        "    # HuBERT Model Configuration\n",
        "    HUBERT_MODEL = 'facebook/hubert-base-ls960'\n",
        "    MAX_AUDIO_LENGTH = 16000 * 17  # 17 seconds max\n",
        "    SAMPLING_RATE = 16000\n",
        "\n",
        "    # Feature extraction strategy\n",
        "    POOLING_STRATEGY = 'mean'\n",
        "    USE_ALL_LAYERS = False\n",
        "    LAYER_TO_USE = -1\n",
        "\n",
        "    # Classifier Configuration\n",
        "    CLASSIFIER = 'svm'\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 8\n",
        "    N_FOLDS = 5\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "    # ‚≠ê SMOTE Configuration\n",
        "    USE_SMOTE = True  # Set to True to use SMOTE\n",
        "    SMOTE_K_NEIGHBORS = 3  # Number of neighbors for SMOTE (must be < smallest class size)\n",
        "    SMOTE_SAMPLING_STRATEGY = 'auto'  # 'auto' or dict like {0: 50, 1: 50}\n",
        "\n",
        "    # Class names (0-indexed)\n",
        "    CLASS_NAMES = {\n",
        "        0: 'Severe Dysarthria',\n",
        "        1: 'Moderate Dysarthria',\n",
        "        2: 'Mild Dysarthria',\n",
        "        3: 'No Dysarthria (ALS)',\n",
        "        4: 'Healthy'\n",
        "    }\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(config.OUTPUT_PATH, exist_ok=True)\n",
        "print(f\"\\n‚úÖ Output directory: {config.OUTPUT_PATH}\")\n",
        "\n",
        "# Verify paths\n",
        "print(f\"\\nüîç Verifying paths...\")\n",
        "print(f\"   Base path exists: {os.path.exists(config.BASE_PATH)}\")\n",
        "print(f\"   Training path exists: {os.path.exists(config.TRAINING_PATH)}\")\n",
        "print(f\"   Excel file exists: {os.path.exists(config.EXCEL_PATH)}\")\n",
        "\n",
        "if not all([os.path.exists(config.BASE_PATH),\n",
        "            os.path.exists(config.TRAINING_PATH),\n",
        "            os.path.exists(config.EXCEL_PATH)]):\n",
        "    raise FileNotFoundError(\"Required paths not found!\")\n",
        "\n",
        "print(f\"\\nüìã Configuration:\")\n",
        "print(f\"   HuBERT Model: {config.HUBERT_MODEL}\")\n",
        "print(f\"   Pooling Strategy: {config.POOLING_STRATEGY}\")\n",
        "print(f\"   Classifier: {config.CLASSIFIER}\")\n",
        "print(f\"   Use SMOTE: {config.USE_SMOTE}\")  # ‚≠ê ADDED\n",
        "print(f\"   Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gkJ7DsKG-vSY",
        "outputId": "11f5ca04-ece8-489e-c2cf-1e36f5cd2204"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Output directory: /content/drive/MyDrive/SAND_Project_Data/hubert_baseline_results\n",
            "\n",
            "üîç Verifying paths...\n",
            "   Base path exists: True\n",
            "   Training path exists: True\n",
            "   Excel file exists: True\n",
            "\n",
            "üìã Configuration:\n",
            "   HuBERT Model: facebook/hubert-base-ls960\n",
            "   Pooling Strategy: mean\n",
            "   Classifier: svm\n",
            "   Use SMOTE: True\n",
            "   Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 4: LOAD DATA\n",
        "# ============================================================================\n",
        "print(\"\\n[2/7] Loading dataset...\")\n",
        "\n",
        "def load_data(excel_path, sheet_name):\n",
        "    \"\"\"Load dataset from Excel\"\"\"\n",
        "    df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "    print(f\"   ‚úÖ Loaded {len(df)} samples from: '{sheet_name}'\")\n",
        "\n",
        "    # Convert to 0-indexed classes\n",
        "    df['Class'] = df['Class'] - 1\n",
        "\n",
        "    # Display distribution\n",
        "    class_dist = df['Class'].value_counts().sort_index()\n",
        "    print(f\"   üìä Class distribution:\")\n",
        "    for cls, count in class_dist.items():\n",
        "        pct = (count / len(df)) * 100\n",
        "        print(f\"      Class {cls} ({config.CLASS_NAMES[cls]}): {count:3d} ({pct:5.2f}%)\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load datasets\n",
        "print(\"\\nüìä Loading data sheets...\")\n",
        "df_train = load_data(config.EXCEL_PATH, config.SHEET_TRAINING_BASELINE)\n",
        "print()\n",
        "df_val = load_data(config.EXCEL_PATH, config.SHEET_VALIDATION_BASELINE)\n",
        "\n",
        "print(f\"\\nüìà Dataset Summary:\")\n",
        "print(f\"   Training samples: {len(df_train):3d}\")\n",
        "print(f\"   Validation samples: {len(df_val):3d}\")\n",
        "print(f\"   Total audio files: {(len(df_train) + len(df_val)) * len(config.AUDIO_TYPES)}\")\n",
        "\n",
        "# Verify no overlap\n",
        "train_ids = set(df_train['ID'].values)\n",
        "val_ids = set(df_val['ID'].values)\n",
        "overlap = train_ids.intersection(val_ids)\n",
        "print(f\"   Overlap check: {'‚úÖ No overlap' if len(overlap) == 0 else f'‚ö† {len(overlap)} overlaps'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "j_SkV6hY-zzf",
        "outputId": "141bd91b-d4e4-434c-9a0a-ba698cb75eea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2/7] Loading dataset...\n",
            "\n",
            "üìä Loading data sheets...\n",
            "   ‚úÖ Loaded 219 samples from: 'Training Baseline - Task 1'\n",
            "   üìä Class distribution:\n",
            "      Class 0 (Severe Dysarthria):   4 ( 1.83%)\n",
            "      Class 1 (Moderate Dysarthria):  22 (10.05%)\n",
            "      Class 2 (Mild Dysarthria):  45 (20.55%)\n",
            "      Class 3 (No Dysarthria (ALS)):  62 (28.31%)\n",
            "      Class 4 (Healthy):  86 (39.27%)\n",
            "\n",
            "   ‚úÖ Loaded 53 samples from: 'Validation Baseline - Task 1'\n",
            "   üìä Class distribution:\n",
            "      Class 0 (Severe Dysarthria):   2 ( 3.77%)\n",
            "      Class 1 (Moderate Dysarthria):   4 ( 7.55%)\n",
            "      Class 2 (Mild Dysarthria):  12 (22.64%)\n",
            "      Class 3 (No Dysarthria (ALS)):  14 (26.42%)\n",
            "      Class 4 (Healthy):  21 (39.62%)\n",
            "\n",
            "üìà Dataset Summary:\n",
            "   Training samples: 219\n",
            "   Validation samples:  53\n",
            "   Total audio files: 2176\n",
            "   Overlap check: ‚úÖ No overlap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 5: LOAD HUBERT MODEL\n",
        "# ============================================================================\n",
        "print(f\"\\n[3/7] Loading HuBERT model: {config.HUBERT_MODEL}\")\n",
        "print(\"‚è± This may take 1-2 minutes for first-time download...\")\n",
        "\n",
        "# Load feature extractor and model\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(config.HUBERT_MODEL)\n",
        "model = HubertModel.from_pretrained(config.HUBERT_MODEL)\n",
        "model = model.to(device)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "print(f\"‚úÖ Model loaded successfully!\")\n",
        "print(f\"   Model size: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M parameters\")\n",
        "print(f\"   Hidden size: {model.config.hidden_size}\")\n",
        "print(f\"   Number of layers: {model.config.num_hidden_layers}\")\n",
        "print(f\"   Sampling rate: {feature_extractor.sampling_rate} Hz\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "45dkgPBA-3If",
        "outputId": "f2cb1f8a-d4b4-4235-b63a-b255912eda04"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[3/7] Loading HuBERT model: facebook/hubert-base-ls960\n",
            "‚è± This may take 1-2 minutes for first-time download...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/hubert-base-ls960 were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded successfully!\n",
            "   Model size: 94.4M parameters\n",
            "   Hidden size: 768\n",
            "   Number of layers: 12\n",
            "   Sampling rate: 16000 Hz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 6: AUDIO PROCESSING FUNCTIONS\n",
        "# ============================================================================\n",
        "def load_audio(audio_path, target_sr=16000, max_length=None):\n",
        "    \"\"\"\n",
        "    Load and preprocess audio file\n",
        "    Args:\n",
        "        audio_path: Path to audio file\n",
        "        target_sr: Target sampling rate\n",
        "        max_length: Maximum audio length in samples\n",
        "    Returns:\n",
        "        audio: Audio waveform as numpy array\n",
        "        sr: Sampling rate\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load audio\n",
        "        audio, sr = librosa.load(audio_path, sr=target_sr, mono=True)\n",
        "\n",
        "        # Trim silence\n",
        "        audio, _ = librosa.effects.trim(audio, top_db=20)\n",
        "\n",
        "        # Limit length if specified\n",
        "        if max_length and len(audio) > max_length:\n",
        "            audio = audio[:max_length]\n",
        "\n",
        "        # Ensure minimum length (1 second)\n",
        "        min_length = target_sr\n",
        "        if len(audio) < min_length:\n",
        "            audio = np.pad(audio, (0, min_length - len(audio)), mode='constant')\n",
        "\n",
        "        return audio, sr\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö† Error loading {audio_path}: {str(e)}\")\n",
        "        # Return silence\n",
        "        return np.zeros(target_sr), target_sr\n",
        "\n",
        "def extract_spectral_features(audio, sr=16000):\n",
        "    \"\"\"\n",
        "    Extract comprehensive spectral features from audio\n",
        "\n",
        "    Args:\n",
        "        audio: Audio waveform\n",
        "        sr: Sampling rate\n",
        "\n",
        "    Returns:\n",
        "        features: Array of spectral features\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # 1. Original spectral features (6 features)\n",
        "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    features.extend([np.mean(spectral_centroids), np.std(spectral_centroids)])\n",
        "\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    features.extend([np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
        "\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    features.extend([np.mean(spectral_bandwidth), np.std(spectral_bandwidth)])\n",
        "\n",
        "    # 2. Spectral Flatness (3 features) - HIGHLY RECOMMENDED\n",
        "    spectral_flatness = librosa.feature.spectral_flatness(y=audio)[0]\n",
        "    features.extend([\n",
        "        np.mean(spectral_flatness),\n",
        "        np.std(spectral_flatness),\n",
        "        np.max(spectral_flatness)\n",
        "    ])\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "def extract_hubert_features(audio, sampling_rate=16000, pooling='mean'):\n",
        "    \"\"\"\n",
        "    Extract HuBERT features from audio\n",
        "\n",
        "    Args:\n",
        "        audio: Audio waveform (numpy array)\n",
        "        sampling_rate: Sampling rate\n",
        "        pooling: Pooling strategy ('mean', 'max', 'mean+max', 'last')\n",
        "\n",
        "    Returns:\n",
        "        features: Extracted features as numpy array\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Preprocess audio\n",
        "        inputs = feature_extractor(\n",
        "            audio,\n",
        "            sampling_rate=sampling_rate,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        # Move to device\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Extract features\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, output_hidden_states=True)\n",
        "\n",
        "        # Get hidden states\n",
        "        if config.USE_ALL_LAYERS:\n",
        "            # Use all hidden layers\n",
        "            hidden_states = outputs.hidden_states\n",
        "            features = torch.stack(hidden_states, dim=0).mean(dim=0)\n",
        "        else:\n",
        "            # Use specific layer\n",
        "            features = outputs.hidden_states[config.LAYER_TO_USE]\n",
        "\n",
        "        # Apply pooling\n",
        "        if pooling == 'mean':\n",
        "            features = features.mean(dim=1)\n",
        "        elif pooling == 'max':\n",
        "            features = features.max(dim=1)[0]\n",
        "        elif pooling == 'mean+max':\n",
        "            mean_pool = features.mean(dim=1)\n",
        "            max_pool = features.max(dim=1)[0]\n",
        "            features = torch.cat([mean_pool, max_pool], dim=-1)\n",
        "        elif pooling == 'last':\n",
        "            features = features[:, -1, :]\n",
        "        else:\n",
        "            features = features.mean(dim=1)\n",
        "\n",
        "        # Convert to numpy\n",
        "        features = features.cpu().numpy().squeeze()\n",
        "\n",
        "        return features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö† Error extracting features: {str(e)}\")\n",
        "        # Return zero features\n",
        "        feature_dim = model.config.hidden_size\n",
        "        if pooling == 'mean+max':\n",
        "            feature_dim *= 2\n",
        "        return np.zeros(feature_dim)\n",
        "\n",
        "print(\"‚úÖ Audio processing functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8QW6j39-4Ti",
        "outputId": "b39fe4e7-5e42-4c96-9798-97a112113add"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Audio processing functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 7: EXTRACT FEATURES FROM ALL AUDIO FILES\n",
        "# ============================================================================\n",
        "print(f\"\\n[4/7] Extracting HuBERT features...\")\n",
        "print(f\"  Strategy: {config.POOLING_STRATEGY} pooling\")\n",
        "print(f\"  Processing {len(df_train)} training + {len(df_val)} validation samples\")\n",
        "print(f\"  Total: {(len(df_train) + len(df_val)) * len(config.AUDIO_TYPES)} audio files\")\n",
        "\n",
        "def extract_features_for_dataset(df, dataset_path, audio_types):\n",
        "    \"\"\"\n",
        "    Extract HuBERT + Spectral features for entire dataset\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with patient IDs and labels\n",
        "        dataset_path: Path to audio files\n",
        "        audio_types: List of audio types to process\n",
        "\n",
        "    Returns:\n",
        "        X: Feature matrix\n",
        "        y: Labels\n",
        "        ids: Patient IDs\n",
        "    \"\"\"\n",
        "    features_list = []\n",
        "    labels_list = []\n",
        "    ids_list = []\n",
        "\n",
        "    print(f\"\\n  Processing {len(df)} patients...\")\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"  Extracting\"):\n",
        "        patient_id = row['ID']\n",
        "        patient_class = row['Class']\n",
        "\n",
        "        patient_features = []\n",
        "\n",
        "        # Process all audio types for this patient\n",
        "        for audio_type in audio_types:\n",
        "            audio_file = f\"{patient_id}_{audio_type}.wav\"\n",
        "            audio_path = os.path.join(dataset_path, audio_type, audio_file)\n",
        "\n",
        "            if os.path.exists(audio_path):\n",
        "                # Load audio\n",
        "                audio, sr = load_audio(\n",
        "                    audio_path,\n",
        "                    target_sr=config.SAMPLING_RATE,\n",
        "                    max_length=config.MAX_AUDIO_LENGTH\n",
        "                )\n",
        "\n",
        "                # Extract HuBERT features\n",
        "                hubert_features = extract_hubert_features(\n",
        "                    audio,\n",
        "                    sampling_rate=sr,\n",
        "                    pooling=config.POOLING_STRATEGY\n",
        "                )\n",
        "\n",
        "                # Extract spectral features\n",
        "                spectral_features = extract_spectral_features(audio, sr)\n",
        "\n",
        "                # Concatenate HuBERT + Spectral features\n",
        "                combined_features = np.concatenate([hubert_features, spectral_features])\n",
        "\n",
        "                patient_features.append(combined_features)\n",
        "            else:\n",
        "                # Use zero features for missing files\n",
        "                feature_dim = model.config.hidden_size\n",
        "                if config.POOLING_STRATEGY == 'mean+max':\n",
        "                    feature_dim *= 2\n",
        "                # Add 9 for spectral features (6 + 3)\n",
        "                feature_dim += 9\n",
        "                patient_features.append(np.zeros(feature_dim))\n",
        "\n",
        "        # Concatenate features from all audio types\n",
        "        combined_features = np.concatenate(patient_features)\n",
        "        features_list.append(combined_features)\n",
        "        labels_list.append(patient_class)\n",
        "        ids_list.append(patient_id)\n",
        "\n",
        "    X = np.array(features_list)\n",
        "    y = np.array(labels_list)\n",
        "    ids = np.array(ids_list)\n",
        "\n",
        "    return X, y, ids\n",
        "\n",
        "# Extract features for training set\n",
        "print(\"\\nüéµ Extracting TRAINING features...\")\n",
        "X_train, y_train, ids_train = extract_features_for_dataset(\n",
        "    df_train,\n",
        "    config.TRAINING_PATH,\n",
        "    config.AUDIO_TYPES\n",
        ")\n",
        "\n",
        "# Extract features for validation set\n",
        "print(\"\\nüéµ Extracting VALIDATION features...\")\n",
        "X_val, y_val, ids_val = extract_features_for_dataset(\n",
        "    df_val,\n",
        "    config.TRAINING_PATH,\n",
        "    config.AUDIO_TYPES\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Feature extraction complete!\")\n",
        "print(f\"  Training: X={X_train.shape}, y={y_train.shape}\")\n",
        "print(f\"  Validation: X={X_val.shape}, y={y_val.shape}\")\n",
        "\n",
        "# Save raw features\n",
        "features_path = os.path.join(config.OUTPUT_PATH, 'hubert_features.npz')\n",
        "np.savez(\n",
        "    features_path,\n",
        "    X_train=X_train, y_train=y_train, ids_train=ids_train,\n",
        "    X_val=X_val, y_val=y_val, ids_val=ids_val\n",
        ")\n",
        "print(f\"  üíæ Features saved to: {features_path}\")\n",
        "\n",
        "# Clear GPU memory\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413,
          "referenced_widgets": [
            "e8feafcae16a45af95372be50c971234",
            "d0227c80f93941b8b2205b72bc75d380",
            "a779eff5542e4932bdc304510f686044",
            "71c8224a374542159ab1241425387697",
            "0651e8acd9d546979095fdd80532efcb",
            "34d1a8ee166946a4bcf76b8d303ba701",
            "9fc4e5fa6c854e26a295d9cf0f0c1d0b",
            "2d1bf910fad64cf883655a2169aaf40a",
            "b03cdaa72f7f4fcb801d501306776a8a",
            "9d9b3b421f5d42bdab11d45685f55fb4",
            "1a3259f392854767ba0b4ea466001772",
            "6cb935b33f82412eafa9221d5631da68",
            "e8b58c1a2a6f4f25807dba583d0d4108",
            "d0edba10e0b24edc8013012391b67055",
            "0e9f3cf7b7e44baeaab515df006aa4cc",
            "9aefe307c78241f48405f24b062d9228",
            "0cf0b05da4e0475291354861a8e5a6cb",
            "eb8ddba6565d4c34856e300cf19f1e4f",
            "52609afa6f2c414babf54205720b6674",
            "d0e397e7cff14730b6fda370dd03fe9b",
            "a2a26a24dbb24085864982c57268126b",
            "48fd09cf9ae64c1bb347b5a0052c7b43"
          ]
        },
        "id": "V9_tdmq7-6LD",
        "outputId": "1ccc85be-87a5-48bc-d277-3519f8d2fc29"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[4/7] Extracting HuBERT features...\n",
            "  Strategy: mean pooling\n",
            "  Processing 219 training + 53 validation samples\n",
            "  Total: 2176 audio files\n",
            "\n",
            "üéµ Extracting TRAINING features...\n",
            "\n",
            "  Processing 219 patients...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Extracting:   0%|          | 0/219 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8feafcae16a45af95372be50c971234"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéµ Extracting VALIDATION features...\n",
            "\n",
            "  Processing 53 patients...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Extracting:   0%|          | 0/53 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cb935b33f82412eafa9221d5631da68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Feature extraction complete!\n",
            "  Training: X=(219, 6216), y=(219,)\n",
            "  Validation: X=(53, 6216), y=(53,)\n",
            "  üíæ Features saved to: /content/drive/MyDrive/SAND_Project_Data/hubert_baseline_results/hubert_features.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 8: PREPROCESS FEATURES\n",
        "# ============================================================================\n",
        "print(\"\\n[5/7] Preprocessing features...\")\n",
        "\n",
        "# Check for problematic values\n",
        "print(f\"   üîç Data quality check:\")\n",
        "print(f\"      NaN in X_train: {np.isnan(X_train).sum()}\")\n",
        "print(f\"      Inf in X_train: {np.isinf(X_train).sum()}\")\n",
        "print(f\"      NaN in X_val: {np.isnan(X_val).sum()}\")\n",
        "print(f\"      Inf in X_val: {np.isinf(X_val).sum()}\")\n",
        "\n",
        "# Clean data\n",
        "X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_val = np.nan_to_num(X_val, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "# Standardize features\n",
        "print(f\"\\n   üîß Standardizing features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "print(f\"   ‚úÖ Features standardized\")\n",
        "print(f\"      Training - Mean: {X_train_scaled.mean():.6f}, Std: {X_train_scaled.std():.6f}\")\n",
        "print(f\"      Validation - Mean: {X_val_scaled.mean():.6f}, Std: {X_val_scaled.std():.6f}\")\n",
        "\n",
        "# Save scaler\n",
        "scaler_path = os.path.join(config.OUTPUT_PATH, 'scaler.pkl')\n",
        "joblib.dump(scaler, scaler_path)\n",
        "print(f\"   üíæ Scaler saved to: {scaler_path}\")\n",
        "\n",
        "# Display feature statistics\n",
        "print(f\"\\n   üìä Feature Statistics:\")\n",
        "print(f\"      Feature dimension: {X_train_scaled.shape[1]}\")\n",
        "print(f\"      Min value: {X_train_scaled.min():.4f}\")\n",
        "print(f\"      Max value: {X_train_scaled.max():.4f}\")\n",
        "print(f\"      Mean: {X_train_scaled.mean():.4f}\")\n",
        "print(f\"      Std: {X_train_scaled.std():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uukaDcc1_dPt",
        "outputId": "a6938125-47b7-4fea-b886-d09abe6da20e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[5/7] Preprocessing features...\n",
            "   üîç Data quality check:\n",
            "      NaN in X_train: 0\n",
            "      Inf in X_train: 0\n",
            "      NaN in X_val: 0\n",
            "      Inf in X_val: 0\n",
            "\n",
            "   üîß Standardizing features...\n",
            "   ‚úÖ Features standardized\n",
            "      Training - Mean: 0.000000, Std: 1.000000\n",
            "      Validation - Mean: 0.019462, Std: 8.833868\n",
            "   üíæ Scaler saved to: /content/drive/MyDrive/SAND_Project_Data/hubert_baseline_results/scaler.pkl\n",
            "\n",
            "   üìä Feature Statistics:\n",
            "      Feature dimension: 6216\n",
            "      Min value: -6.1489\n",
            "      Max value: 14.7648\n",
            "      Mean: 0.0000\n",
            "      Std: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 8.5: APPLY SMOTE TO BALANCE CLASSES\n",
        "# ============================================================================\n",
        "if config.USE_SMOTE:\n",
        "    print(\"\\n[5.5/7] Applying SMOTE for class balancing...\")\n",
        "\n",
        "    # Show original distribution\n",
        "    print(f\"\\n üìä Original class distribution:\")\n",
        "    unique, counts = np.unique(y_train, return_counts=True)\n",
        "    for cls, count in zip(unique, counts):\n",
        "        print(f\"   Class {cls} ({config.CLASS_NAMES[cls]:25s}): {count:3d} samples\")\n",
        "\n",
        "    # Determine k_neighbors based on smallest class\n",
        "    min_class_size = min(counts)\n",
        "    k_neighbors = min(config.SMOTE_K_NEIGHBORS, min_class_size - 1)\n",
        "\n",
        "    if k_neighbors < 1:\n",
        "        print(f\"\\n ‚ö†Ô∏è  WARNING: Smallest class has only {min_class_size} samples.\")\n",
        "        print(f\"    SMOTE requires at least 2 samples per class. Skipping SMOTE.\")\n",
        "        X_train_resampled = X_train_scaled\n",
        "        y_train_resampled = y_train\n",
        "    else:\n",
        "        print(f\"\\n üîß Applying SMOTE with k_neighbors={k_neighbors}...\")\n",
        "\n",
        "        try:\n",
        "            smote = SMOTE(\n",
        "                sampling_strategy=config.SMOTE_SAMPLING_STRATEGY,\n",
        "                k_neighbors=k_neighbors,\n",
        "                random_state=config.RANDOM_SEED\n",
        "            )\n",
        "\n",
        "            X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "            # Show new distribution\n",
        "            print(f\"\\n ‚úÖ SMOTE applied successfully!\")\n",
        "            print(f\"\\n üìä New class distribution after SMOTE:\")\n",
        "            unique_new, counts_new = np.unique(y_train_resampled, return_counts=True)\n",
        "            for cls, count in zip(unique_new, counts_new):\n",
        "                print(f\"   Class {cls} ({config.CLASS_NAMES[cls]:25s}): {count:3d} samples\")\n",
        "\n",
        "            print(f\"\\n üìà Dataset size change:\")\n",
        "            print(f\"   Before SMOTE: {len(y_train)} samples\")\n",
        "            print(f\"   After SMOTE:  {len(y_train_resampled)} samples\")\n",
        "            print(f\"   Increase:     +{len(y_train_resampled) - len(y_train)} samples (+{(len(y_train_resampled)/len(y_train) - 1)*100:.1f}%)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n ‚ö†Ô∏è  Error applying SMOTE: {str(e)}\")\n",
        "            print(f\"    Using original unbalanced data.\")\n",
        "            X_train_resampled = X_train_scaled\n",
        "            y_train_resampled = y_train\n",
        "else:\n",
        "    print(\"\\n[5.5/7] SMOTE disabled - using original class distribution\")\n",
        "    X_train_resampled = X_train_scaled\n",
        "    y_train_resampled = y_train\n",
        "\n",
        "# Keep validation set unchanged\n",
        "X_val_scaled_final = X_val_scaled\n",
        "y_val_final = y_val\n",
        "\n",
        "print(f\"\\n ‚úÖ Ready for training!\")\n",
        "print(f\"   Training samples: {len(y_train_resampled)}\")\n",
        "print(f\"   Validation samples: {len(y_val_final)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUg2KvGg_k0B",
        "outputId": "6d62d946-2461-49a0-c79b-d27a78fa3bcb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[5.5/7] Applying SMOTE for class balancing...\n",
            "\n",
            " üìä Original class distribution:\n",
            "   Class 0 (Severe Dysarthria        ):   4 samples\n",
            "   Class 1 (Moderate Dysarthria      ):  22 samples\n",
            "   Class 2 (Mild Dysarthria          ):  45 samples\n",
            "   Class 3 (No Dysarthria (ALS)      ):  62 samples\n",
            "   Class 4 (Healthy                  ):  86 samples\n",
            "\n",
            " üîß Applying SMOTE with k_neighbors=3...\n",
            "\n",
            " ‚úÖ SMOTE applied successfully!\n",
            "\n",
            " üìä New class distribution after SMOTE:\n",
            "   Class 0 (Severe Dysarthria        ):  86 samples\n",
            "   Class 1 (Moderate Dysarthria      ):  86 samples\n",
            "   Class 2 (Mild Dysarthria          ):  86 samples\n",
            "   Class 3 (No Dysarthria (ALS)      ):  86 samples\n",
            "   Class 4 (Healthy                  ):  86 samples\n",
            "\n",
            " üìà Dataset size change:\n",
            "   Before SMOTE: 219 samples\n",
            "   After SMOTE:  430 samples\n",
            "   Increase:     +211 samples (+96.3%)\n",
            "\n",
            " ‚úÖ Ready for training!\n",
            "   Training samples: 430\n",
            "   Validation samples: 53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 9: TRAIN CLASSIFIER\n",
        "# ============================================================================\n",
        "print(f\"\\n[6/7] Training classifier: {config.CLASSIFIER.upper()}\")\n",
        "\n",
        "def get_classifier(classifier_type):\n",
        "    \"\"\"Get classifier based on type\"\"\"\n",
        "    if classifier_type == 'logistic':\n",
        "        return LogisticRegression(\n",
        "            max_iter=1000,\n",
        "            random_state=config.RANDOM_SEED,\n",
        "            class_weight='balanced',\n",
        "            C=1.0\n",
        "        )\n",
        "    elif classifier_type == 'svm':\n",
        "        return SVC(\n",
        "            kernel='rbf',\n",
        "            C=10.0,\n",
        "            gamma='scale',\n",
        "            random_state=config.RANDOM_SEED,\n",
        "            class_weight='balanced',\n",
        "            probability=True\n",
        "        )\n",
        "    elif classifier_type == 'rf':\n",
        "        return RandomForestClassifier(\n",
        "            n_estimators=200,\n",
        "            max_depth=20,\n",
        "            random_state=config.RANDOM_SEED,\n",
        "            class_weight='balanced',\n",
        "            n_jobs=-1\n",
        "        )\n",
        "    elif classifier_type == 'gb':\n",
        "        return GradientBoostingClassifier(\n",
        "            n_estimators=200,\n",
        "            max_depth=5,\n",
        "            learning_rate=0.1,\n",
        "            random_state=config.RANDOM_SEED\n",
        "        )\n",
        "    else:\n",
        "        return LogisticRegression(\n",
        "            max_iter=1000,\n",
        "            random_state=config.RANDOM_SEED,\n",
        "            class_weight='balanced'\n",
        "        )\n",
        "\n",
        "# Initialize and train classifier\n",
        "print(f\"\\n üéØ Training {config.CLASSIFIER.upper()} classifier...\")\n",
        "classifier = get_classifier(config.CLASSIFIER)\n",
        "\n",
        "# ‚≠ê Train on SMOTE-resampled data\n",
        "classifier.fit(X_train_resampled, y_train_resampled)\n",
        "print(f\"   ‚úÖ Training complete!\")\n",
        "\n",
        "# Cross-validation score on training set\n",
        "print(f\"\\n üìä Cross-validation on training set...\")\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    classifier,\n",
        "    X_train_resampled,  # ‚≠ê Use resampled data\n",
        "    y_train_resampled,  # ‚≠ê Use resampled labels\n",
        "    cv=config.N_FOLDS,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(f\"   CV F1 Scores: {cv_scores}\")\n",
        "print(f\"   Mean CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "\n",
        "# Save model\n",
        "model_path = os.path.join(config.OUTPUT_PATH, 'classifier.pkl')\n",
        "joblib.dump(classifier, model_path)\n",
        "print(f\"\\n üíæ Classifier saved to: {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzAJh8Tt_mR9",
        "outputId": "52cd0824-5597-44df-e7a9-e05b2baef3ea"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[6/7] Training classifier: SVM\n",
            "\n",
            " üéØ Training SVM classifier...\n",
            "   ‚úÖ Training complete!\n",
            "\n",
            " üìä Cross-validation on training set...\n",
            "   CV F1 Scores: [0.81408835 0.84808769 0.76733997 0.87047619 0.86630411]\n",
            "   Mean CV F1: 0.8333 (+/- 0.0385)\n",
            "\n",
            " üíæ Classifier saved to: /content/drive/MyDrive/SAND_Project_Data/hubert_baseline_results/classifier.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 10: EVALUATE ON VALIDATION SET\n",
        "# ============================================================================\n",
        "print(\"\\n[7/7] Evaluating on validation set...\")\n",
        "\n",
        "# ‚≠ê Predict on original (non-SMOTE) validation set\n",
        "y_val_pred = classifier.predict(X_val_scaled_final)\n",
        "y_val_pred_proba = classifier.predict_proba(X_val_scaled_final)\n",
        "\n",
        "# Compute metrics\n",
        "accuracy = accuracy_score(y_val_final, y_val_pred)\n",
        "f1_macro = f1_score(y_val_final, y_val_pred, average='macro')\n",
        "f1_weighted = f1_score(y_val_final, y_val_pred, average='weighted')\n",
        "precision = precision_score(y_val_final, y_val_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_val_final, y_val_pred, average='macro', zero_division=0)\n",
        "kappa = cohen_kappa_score(y_val_final, y_val_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ VALIDATION SET RESULTS - HUBERT BASELINE\" + (\" (WITH SMOTE)\" if config.USE_SMOTE else \"\"))\n",
        "print(\"=\"*80)\n",
        "print(f\"Accuracy:              {accuracy:.4f}\")\n",
        "print(f\"F1 Score (Macro):      {f1_macro:.4f} ‚≠ê Main SAND metric\")\n",
        "print(f\"F1 Score (Weighted):   {f1_weighted:.4f}\")\n",
        "print(f\"Precision (Macro):     {precision:.4f}\")\n",
        "print(f\"Recall (Macro):        {recall:.4f}\")\n",
        "print(f\"Cohen's Kappa:         {kappa:.4f}\")\n",
        "\n",
        "# Per-class metrics\n",
        "print(\"\\n\" + \"-\"*80)\n",
        "print(\"PER-CLASS METRICS\")\n",
        "print(\"-\"*80)\n",
        "available_classes = sorted(np.unique(y_val_final))\n",
        "class_labels = [config.CLASS_NAMES[int(i)] for i in available_classes]\n",
        "print(classification_report(y_val_final, y_val_pred, target_names=class_labels, zero_division=0))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_val_final, y_val_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Per-class F1\n",
        "f1_per_class = f1_score(y_val_final, y_val_pred, average=None, zero_division=0)\n",
        "print(\"\\nF1 Score per Class:\")\n",
        "for cls, f1_val in zip(available_classes, f1_per_class):\n",
        "    label_name = config.CLASS_NAMES[int(cls)]\n",
        "    print(f\"   Class {cls} ({label_name:25s}): {f1_val:.4f}\")\n",
        "\n",
        "# Comparison with baselines\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä COMPARISON WITH BASELINES\")\n",
        "print(\"=\"*80)\n",
        "sand_vit = 0.606\n",
        "xgboost_baseline = 0.326\n",
        "hubert_no_smote = 0.5324  # Your previous result without SMOTE\n",
        "\n",
        "print(f\"HuBERT + SMOTE (This model): {f1_macro:.4f} üöÄ\")\n",
        "print(f\"HuBERT (No SMOTE):           {hubert_no_smote:.4f}\")\n",
        "print(f\"SAND ViT Baseline:           {sand_vit:.4f}\")\n",
        "print(f\"XGBoost + OpenSMILE:         {xgboost_baseline:.4f}\")\n",
        "\n",
        "if f1_macro > sand_vit:\n",
        "    improvement = f1_macro - sand_vit\n",
        "    print(f\"\\n‚úÖ BEATS SAND baseline by +{improvement:.4f} (+{improvement/sand_vit*100:.1f}%)!\")\n",
        "else:\n",
        "    gap = sand_vit - f1_macro\n",
        "    print(f\"\\nGap to SAND: -{gap:.4f}\")\n",
        "\n",
        "if f1_macro > hubert_no_smote:\n",
        "    improvement_smote = f1_macro - hubert_no_smote\n",
        "    print(f\"SMOTE Improvement: +{improvement_smote:.4f} (+{improvement_smote/hubert_no_smote*100:.1f}%)\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    'model': 'HuBERT + SMOTE' if config.USE_SMOTE else 'HuBERT',\n",
        "    'hubert_model': config.HUBERT_MODEL,\n",
        "    'pooling_strategy': config.POOLING_STRATEGY,\n",
        "    'classifier': config.CLASSIFIER,\n",
        "    'use_smote': config.USE_SMOTE,\n",
        "    'smote_k_neighbors': k_neighbors if config.USE_SMOTE else None,\n",
        "    'n_train_original': int(len(y_train)),\n",
        "    'n_train_after_smote': int(len(y_train_resampled)),\n",
        "    'accuracy': float(accuracy),\n",
        "    'f1_macro': float(f1_macro),\n",
        "    'f1_weighted': float(f1_weighted),\n",
        "    'precision': float(precision),\n",
        "    'recall': float(recall),\n",
        "    'kappa': float(kappa),\n",
        "    'f1_per_class': {int(cls): float(f1_val) for cls, f1_val in zip(available_classes, f1_per_class)},\n",
        "    'cv_scores': cv_scores.tolist(),\n",
        "    'cv_mean': float(cv_scores.mean()),\n",
        "    'cv_std': float(cv_scores.std()),\n",
        "    'confusion_matrix': cm.tolist(),\n",
        "    'feature_dim': int(X_train.shape[1]),\n",
        "    'n_val': int(len(y_val_final)),\n",
        "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "\n",
        "results_path = os.path.join(config.OUTPUT_PATH, 'results_with_smote.json' if config.USE_SMOTE else 'results.json')\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(f\"\\nüíæ Results saved to: {results_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsRp8d6QEjdr",
        "outputId": "53192f1b-d8e0-4117-aea9-6651585ebde5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[7/7] Evaluating on validation set...\n",
            "\n",
            "================================================================================\n",
            "üéØ VALIDATION SET RESULTS - HUBERT BASELINE (WITH SMOTE)\n",
            "================================================================================\n",
            "Accuracy:              0.6981\n",
            "F1 Score (Macro):      0.5821 ‚≠ê Main SAND metric\n",
            "F1 Score (Weighted):   0.6719\n",
            "Precision (Macro):     0.5767\n",
            "Recall (Macro):        0.6071\n",
            "Cohen's Kappa:         0.5656\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "PER-CLASS METRICS\n",
            "--------------------------------------------------------------------------------\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  Severe Dysarthria       0.00      0.00      0.00         2\n",
            "Moderate Dysarthria       0.80      1.00      0.89         4\n",
            "    Mild Dysarthria       0.75      0.75      0.75        12\n",
            "No Dysarthria (ALS)       0.67      0.43      0.52        14\n",
            "            Healthy       0.67      0.86      0.75        21\n",
            "\n",
            "           accuracy                           0.70        53\n",
            "          macro avg       0.58      0.61      0.58        53\n",
            "       weighted avg       0.67      0.70      0.67        53\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 0  1  0  0  1]\n",
            " [ 0  4  0  0  0]\n",
            " [ 0  0  9  1  2]\n",
            " [ 0  0  2  6  6]\n",
            " [ 0  0  1  2 18]]\n",
            "\n",
            "F1 Score per Class:\n",
            "   Class 0 (Severe Dysarthria        ): 0.0000\n",
            "   Class 1 (Moderate Dysarthria      ): 0.8889\n",
            "   Class 2 (Mild Dysarthria          ): 0.7500\n",
            "   Class 3 (No Dysarthria (ALS)      ): 0.5217\n",
            "   Class 4 (Healthy                  ): 0.7500\n",
            "\n",
            "================================================================================\n",
            "üìä COMPARISON WITH BASELINES\n",
            "================================================================================\n",
            "HuBERT + SMOTE (This model): 0.5821 üöÄ\n",
            "HuBERT (No SMOTE):           0.5324\n",
            "SAND ViT Baseline:           0.6060\n",
            "XGBoost + OpenSMILE:         0.3260\n",
            "\n",
            "Gap to SAND: -0.0239\n",
            "SMOTE Improvement: +0.0497 (+9.3%)\n",
            "================================================================================\n",
            "\n",
            "üíæ Results saved to: /content/drive/MyDrive/SAND_Project_Data/hubert_baseline_results/results_with_smote.json\n"
          ]
        }
      ]
    }
  ]
}