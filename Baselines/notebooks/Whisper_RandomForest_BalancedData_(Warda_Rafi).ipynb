{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60846c0d70a547abacac065f5eaf748e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_706ce753b6d240fc91b6ac52f188792a",
              "IPY_MODEL_4677c28f167a4d03bea46ef857282b61",
              "IPY_MODEL_899aded9ff9243dd88ab8b9e04d453a6"
            ],
            "layout": "IPY_MODEL_d448decd1d234f3aa03e029d7feb9399"
          }
        },
        "706ce753b6d240fc91b6ac52f188792a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5520f44d77b64e6da82df27a2ff384f0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1f65715e9e5440e2a494522ef56e17da",
            "value": "Training:‚Äá100%"
          }
        },
        "4677c28f167a4d03bea46ef857282b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40e0c15eef1b4d5ba0bb248d4fa2efb8",
            "max": 219,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd78fc2336314419beddd530ec77a316",
            "value": 219
          }
        },
        "899aded9ff9243dd88ab8b9e04d453a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5c8f8e3956c43459d09031233f0cc8f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c1c6270834734029a76786de82c33bb8",
            "value": "‚Äá219/219‚Äá[04:28&lt;00:00,‚Äá‚Äá1.23s/it]"
          }
        },
        "d448decd1d234f3aa03e029d7feb9399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5520f44d77b64e6da82df27a2ff384f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f65715e9e5440e2a494522ef56e17da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40e0c15eef1b4d5ba0bb248d4fa2efb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd78fc2336314419beddd530ec77a316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5c8f8e3956c43459d09031233f0cc8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c6270834734029a76786de82c33bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3530fbb4a444923845baa0147c3ea7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d56a6a60aa54c0eb780a726fbf84c96",
              "IPY_MODEL_04ae530d4bca461891682b4f955e01ab",
              "IPY_MODEL_da713abbb35941c69cd1a75ed1128791"
            ],
            "layout": "IPY_MODEL_15ee67273c574214b5573e74aed2b1e0"
          }
        },
        "7d56a6a60aa54c0eb780a726fbf84c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fddeb43f1114f62a41c715d7a19e033",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9502b6815aa94dd7a5e085009a400558",
            "value": "Validation:‚Äá100%"
          }
        },
        "04ae530d4bca461891682b4f955e01ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7587e925c094c26a3b54bdae1961b72",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e14a89049534eb29950a8aaf5fd0c76",
            "value": 53
          }
        },
        "da713abbb35941c69cd1a75ed1128791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab855d957c34b579ba6ed9825dc7016",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_03f06e8744d84ae4ae4107b6bc36b210",
            "value": "‚Äá53/53‚Äá[01:00&lt;00:00,‚Äá‚Äá1.38s/it]"
          }
        },
        "15ee67273c574214b5573e74aed2b1e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fddeb43f1114f62a41c715d7a19e033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9502b6815aa94dd7a5e085009a400558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7587e925c094c26a3b54bdae1961b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e14a89049534eb29950a8aaf5fd0c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aab855d957c34b579ba6ed9825dc7016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03f06e8744d84ae4ae4107b6bc36b210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sbGCOmie-fZ9",
        "outputId": "555fec73-2ade-49a1-af1b-94e768603dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Whisper \n",
            "Random Forest Classifier \n",
            "Balanced Dataset\n",
            "================================================================================\n",
            "Mounted at /content/drive\n",
            "\n",
            "[Installing packages...]\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: SETUP AND INSTALLATION\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"Whisper \\nRandom Forest Classifier \\nBalanced Dataset\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Install required packages\n",
        "print(\"\\n[Installing packages...]\")\n",
        "!pip uninstall -y transformers huggingface_hub tokenizers -q\n",
        "!pip install transformers==4.40.0 -q\n",
        "!pip install torch torchaudio -q\n",
        "!pip install scikit-learn pandas numpy -q\n",
        "!pip install librosa soundfile -q\n",
        "!pip install imbalanced-learn -q\n",
        "!pip install matplotlib seaborn -q\n",
        "print(\"‚úÖ Installation complete!\")\n",
        "\n",
        "print(\"\\nüìÑ Restarting runtime...\")\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 2: IMPORTS (RUN AFTER RESTART)\n",
        "# ============================================================================\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Replace HuBERT with Whisper\n",
        "from transformers import WhisperModel, WhisperFeatureExtractor, WhisperProcessor\n",
        "\n",
        "# Replace SVM with Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    confusion_matrix, classification_report, cohen_kappa_score\n",
        ")\n",
        "\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from tqdm.auto import tqdm\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Mount Drive again after restart\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"‚úÖ Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "B3OmqFLz-nE2",
        "outputId": "f80adcb6-f90f-4ac9-a07d-6cfde11b691c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Using device: cuda\n",
            "‚úÖ All imports successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 3: OPTIMIZED CONFIGURATION\n",
        "# ============================================================================\n",
        "class Config:\n",
        "    \"\"\"Optimized Configuration for Maximum Performance\"\"\"\n",
        "\n",
        "    # Paths\n",
        "    BASE_PATH = '/content/drive/MyDrive/SAND_Project_Data'\n",
        "    TRAINING_PATH = os.path.join(BASE_PATH, 'training')\n",
        "    EXCEL_PATH = os.path.join(BASE_PATH, 'sand_task_1.xlsx')\n",
        "    OUTPUT_PATH = os.path.join(BASE_PATH, 'optimized_whisper_rf_v2')\n",
        "\n",
        "    # Sheet names\n",
        "    SHEET_TRAINING = 'Training Baseline - Task 1'\n",
        "    SHEET_VALIDATION = 'Validation Baseline - Task 1'\n",
        "\n",
        "    # Audio types\n",
        "    AUDIO_TYPES = ['phonationA', 'phonationE', 'phonationI', 'phonationO', 'phonationU',\n",
        "                   'rhythmKA', 'rhythmPA', 'rhythmTA']\n",
        "\n",
        "    # ========================================================================\n",
        "    # OPTIMIZED WHISPER CONFIGURATION\n",
        "    # ========================================================================\n",
        "    WHISPER_MODEL = 'openai/whisper-base'\n",
        "    SAMPLING_RATE = 16000\n",
        "    # CHANGED: Maximum audio length set to 10 seconds (no padding beyond actual audio)\n",
        "    MAX_AUDIO_LENGTH_SEC = 17  # Maximum 10 seconds\n",
        "    MAX_AUDIO_LENGTH = 16000 * MAX_AUDIO_LENGTH_SEC  # 10 seconds in samples\n",
        "\n",
        "    # Multi-layer feature extraction (CRITICAL FOR PERFORMANCE)\n",
        "    USE_MULTI_LAYER = True\n",
        "    LAYERS_TO_USE = [-4, -3, -2, -1]  # Last 4 layers\n",
        "\n",
        "    # Multi-pooling strategy (CRITICAL FOR PERFORMANCE)\n",
        "    USE_MULTI_POOLING = True\n",
        "    POOLING_STRATEGIES = ['mean', 'std', 'max', 'min']  # 4 pooling methods\n",
        "\n",
        "    # Statistical features (HELPS WITH DYSARTHRIA PATTERNS)\n",
        "    USE_STATISTICAL_FEATURES = True\n",
        "\n",
        "    # CHANGED: Audio processing - no padding, slice to actual content only\n",
        "    AUDIO_TRIM_DB = 15  # Lower threshold for dysarthric speech\n",
        "    AUDIO_NORMALIZE = True\n",
        "    MIN_AUDIO_LENGTH_SEC = 2  # Minimum 1 second\n",
        "    # ADDED: Flag to disable padding\n",
        "    USE_PADDING = False  # Changed from implicit True to explicit False\n",
        "\n",
        "    # ========================================================================\n",
        "    # PREPROCESSING OPTIMIZATIONS\n",
        "    # ========================================================================\n",
        "    USE_ROBUST_SCALING = True  # Better for outliers\n",
        "\n",
        "    # PCA Configuration\n",
        "    USE_PCA = True\n",
        "    PCA_VARIANCE = 0.97  # Retain 97% variance\n",
        "\n",
        "    # ========================================================================\n",
        "    # DATA BALANCING (CRITICAL FOR MINORITY CLASSES)\n",
        "    # ========================================================================\n",
        "    USE_SMOTE = True\n",
        "    SMOTE_STRATEGY = 'not majority'  # Oversample all except majority\n",
        "    SMOTE_K_NEIGHBORS = 2  # Lower for small classes\n",
        "\n",
        "    # ========================================================================\n",
        "    # OPTIMIZED RANDOM FOREST HYPERPARAMETERS\n",
        "    # ========================================================================\n",
        "    RF_CONFIG = {\n",
        "        'n_estimators': 500,\n",
        "        'max_depth': 20,\n",
        "        'min_samples_split': 2,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'sqrt',\n",
        "        'bootstrap': True,\n",
        "        'class_weight': 'balanced',\n",
        "        'random_state': RANDOM_SEED,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    # Cross-validation\n",
        "    N_FOLDS = 5\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "    # Class names\n",
        "    CLASS_NAMES = {\n",
        "        0: 'Severe Dysarthria',\n",
        "        1: 'Moderate Dysarthria',\n",
        "        2: 'Mild Dysarthria',\n",
        "        3: 'No Dysarthria (ALS)',\n",
        "        4: 'Healthy'\n",
        "    }\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìã OPTIMIZED CONFIGURATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Whisper Model: {config.WHISPER_MODEL}\")\n",
        "print(f\"Multi-Layer Extraction: {config.USE_MULTI_LAYER} ({len(config.LAYERS_TO_USE)} layers)\")\n",
        "print(f\"Multi-Pooling: {config.USE_MULTI_POOLING} ({len(config.POOLING_STRATEGIES)} strategies)\")\n",
        "print(f\"Statistical Features: {config.USE_STATISTICAL_FEATURES}\")\n",
        "print(f\"PCA: {config.USE_PCA} (variance={config.PCA_VARIANCE})\")\n",
        "print(f\"SMOTE: {config.USE_SMOTE}\")\n",
        "print(f\"Random Forest Estimators: {config.RF_CONFIG['n_estimators']}\")\n",
        "# CHANGED: Display 10 seconds instead of 15\n",
        "print(f\"Max Audio Length: {config.MAX_AUDIO_LENGTH_SEC} seconds (NO PADDING)\")\n",
        "print(f\"Use Padding: {config.USE_PADDING}\")\n",
        "print(f\"Device: {device}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verify paths\n",
        "print(f\"\\nüìÇ Verifying paths...\")\n",
        "assert os.path.exists(config.BASE_PATH), \"Base path not found!\"\n",
        "assert os.path.exists(config.TRAINING_PATH), \"Training path not found!\"\n",
        "assert os.path.exists(config.EXCEL_PATH), \"Excel file not found!\"\n",
        "print(\"‚úÖ All paths verified!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkJ7DsKG-vSY",
        "outputId": "b9e04a95-3c27-42f0-ae23-bcfe39cc7c46"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìã OPTIMIZED CONFIGURATION\n",
            "================================================================================\n",
            "Whisper Model: openai/whisper-base\n",
            "Multi-Layer Extraction: True (4 layers)\n",
            "Multi-Pooling: True (4 strategies)\n",
            "Statistical Features: True\n",
            "PCA: True (variance=0.97)\n",
            "SMOTE: True\n",
            "Random Forest Estimators: 500\n",
            "Max Audio Length: 17 seconds (NO PADDING)\n",
            "Use Padding: False\n",
            "Device: cuda\n",
            "================================================================================\n",
            "\n",
            "üìÇ Verifying paths...\n",
            "‚úÖ All paths verified!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 4: LOAD DATASETS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[1/9] LOADING DATASETS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def load_data(excel_path, sheet_name):\n",
        "    \"\"\"Load dataset from Excel\"\"\"\n",
        "    df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "    print(f\"\\n‚úÖ Loaded {len(df)} samples from: '{sheet_name}'\")\n",
        "\n",
        "    # Convert to 0-indexed classes\n",
        "    df['Class'] = df['Class'] - 1\n",
        "\n",
        "    # Display distribution\n",
        "    print(f\"üìä Class distribution:\")\n",
        "    class_dist = df['Class'].value_counts().sort_index()\n",
        "    for cls, count in class_dist.items():\n",
        "        pct = (count / len(df)) * 100\n",
        "        print(f\"  Class {cls} ({config.CLASS_NAMES[cls]:25s}): {count:3d} ({pct:5.2f}%)\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load training and validation sets\n",
        "df_train = load_data(config.EXCEL_PATH, config.SHEET_TRAINING)\n",
        "df_val = load_data(config.EXCEL_PATH, config.SHEET_VALIDATION)\n",
        "\n",
        "print(f\"\\nüìà Summary:\")\n",
        "print(f\"  Training samples: {len(df_train)}\")\n",
        "print(f\"  Validation samples: {len(df_val)}\")\n",
        "print(f\"  Total audio files: {(len(df_train) + len(df_val)) * len(config.AUDIO_TYPES)}\")\n",
        "\n",
        "# Verify no overlap\n",
        "train_ids = set(df_train['ID'].values)\n",
        "val_ids = set(df_val['ID'].values)\n",
        "overlap = train_ids.intersection(val_ids)\n",
        "print(f\"  Overlap check: {'‚úÖ No overlap' if len(overlap) == 0 else f'‚ö† {len(overlap)} overlapping IDs'}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_SkV6hY-zzf",
        "outputId": "091d7a89-11b2-43c9-bc93-da8deb31badc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[1/9] LOADING DATASETS\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Loaded 219 samples from: 'Training Baseline - Task 1'\n",
            "üìä Class distribution:\n",
            "  Class 0 (Severe Dysarthria        ):   4 ( 1.83%)\n",
            "  Class 1 (Moderate Dysarthria      ):  22 (10.05%)\n",
            "  Class 2 (Mild Dysarthria          ):  45 (20.55%)\n",
            "  Class 3 (No Dysarthria (ALS)      ):  62 (28.31%)\n",
            "  Class 4 (Healthy                  ):  86 (39.27%)\n",
            "\n",
            "‚úÖ Loaded 53 samples from: 'Validation Baseline - Task 1'\n",
            "üìä Class distribution:\n",
            "  Class 0 (Severe Dysarthria        ):   2 ( 3.77%)\n",
            "  Class 1 (Moderate Dysarthria      ):   4 ( 7.55%)\n",
            "  Class 2 (Mild Dysarthria          ):  12 (22.64%)\n",
            "  Class 3 (No Dysarthria (ALS)      ):  14 (26.42%)\n",
            "  Class 4 (Healthy                  ):  21 (39.62%)\n",
            "\n",
            "üìà Summary:\n",
            "  Training samples: 219\n",
            "  Validation samples: 53\n",
            "  Total audio files: 2176\n",
            "  Overlap check: ‚úÖ No overlap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 5: LOAD WHISPER MODEL\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[2/9] LOADING WHISPER MODEL\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Model: {config.WHISPER_MODEL}\")\n",
        "print(\"‚è± This may take 1-2 minutes for first-time download...\")\n",
        "\n",
        "# Load feature extractor and model\n",
        "processor = WhisperProcessor.from_pretrained(config.WHISPER_MODEL)\n",
        "whisper_model = WhisperModel.from_pretrained(config.WHISPER_MODEL)\n",
        "whisper_model = whisper_model.to(device)\n",
        "whisper_model.eval()  # Set to evaluation mode\n",
        "\n",
        "print(f\"\\n‚úÖ Whisper loaded successfully!\")\n",
        "print(f\"  Model size: {sum(p.numel() for p in whisper_model.parameters()) / 1e6:.1f}M parameters\")\n",
        "print(f\"  Hidden size: {whisper_model.config.d_model}\")\n",
        "print(f\"  Number of encoder layers: {whisper_model.config.encoder_layers}\")\n",
        "print(f\"  Sampling rate: {processor.feature_extractor.sampling_rate} Hz\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45dkgPBA-3If",
        "outputId": "488296ac-eae3-46c6-fba4-44f6ebfe661a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[2/9] LOADING WHISPER MODEL\n",
            "================================================================================\n",
            "Model: openai/whisper-base\n",
            "‚è± This may take 1-2 minutes for first-time download...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Whisper loaded successfully!\n",
            "  Model size: 72.6M parameters\n",
            "  Hidden size: 512\n",
            "  Number of encoder layers: 6\n",
            "  Sampling rate: 16000 Hz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 6: ENHANCED AUDIO PROCESSING FUNCTIONS (NO PADDING VERSION)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[3/9] DEFINING ENHANCED AUDIO PROCESSING (NO PADDING)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def load_audio_enhanced(audio_path, target_sr=16000, max_length=None):\n",
        "    \"\"\"\n",
        "    Enhanced audio loading - EXTRACTS ONLY ACTUAL AUDIO CONTENT (NO PADDING)\n",
        "\n",
        "    Args:\n",
        "        audio_path: Path to audio file\n",
        "        target_sr: Target sampling rate\n",
        "        max_length: Maximum audio length in samples (will slice if longer)\n",
        "\n",
        "    Returns:\n",
        "        audio: Preprocessed audio waveform (actual content only)\n",
        "        sr: Sampling rate\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load audio\n",
        "        audio, sr = librosa.load(audio_path, sr=target_sr, mono=True)\n",
        "\n",
        "        # Advanced trimming with lower threshold for dysarthric speech\n",
        "        audio, _ = librosa.effects.trim(audio, top_db=config.AUDIO_TRIM_DB)\n",
        "\n",
        "        # Normalize amplitude\n",
        "        if config.AUDIO_NORMALIZE:\n",
        "            audio = librosa.util.normalize(audio)\n",
        "\n",
        "        # CHANGED: Slice to max_length instead of padding\n",
        "        if max_length and len(audio) > max_length:\n",
        "            audio = audio[:max_length]\n",
        "\n",
        "        # CHANGED: Only pad if audio is extremely short (< 1 second)\n",
        "        min_length = target_sr * config.MIN_AUDIO_LENGTH_SEC\n",
        "        if len(audio) < min_length:\n",
        "            # Pad only to minimum viable length (1 second)\n",
        "            audio = np.pad(audio, (0, min_length - len(audio)), mode='constant')\n",
        "\n",
        "        # REMOVED: No padding to 15 seconds - use actual audio length only\n",
        "\n",
        "        return audio, sr\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö† Error loading {audio_path}: {str(e)}\")\n",
        "        # Return minimum silence as fallback\n",
        "        return np.zeros(target_sr * config.MIN_AUDIO_LENGTH_SEC), target_sr\n",
        "\n",
        "def extract_statistical_features(audio, sr=16000):\n",
        "    \"\"\"\n",
        "    Extract statistical and acoustic features from audio\n",
        "    These help capture dysarthria-specific patterns\n",
        "\n",
        "    Args:\n",
        "        audio: Audio waveform\n",
        "        sr: Sampling rate\n",
        "\n",
        "    Returns:\n",
        "        features: Array of statistical features\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # Time-domain statistics\n",
        "    features.extend([\n",
        "        np.mean(audio),           # Mean amplitude\n",
        "        np.std(audio),            # Standard deviation\n",
        "        skew(audio),              # Skewness\n",
        "        kurtosis(audio),          # Kurtosis\n",
        "        np.max(np.abs(audio)),    # Peak amplitude\n",
        "        np.median(audio),         # Median\n",
        "        np.percentile(audio, 25), # 25th percentile\n",
        "        np.percentile(audio, 75)  # 75th percentile\n",
        "    ])\n",
        "\n",
        "    # Zero crossing rate (voice quality indicator)\n",
        "    zcr = librosa.feature.zero_crossing_rate(audio)[0]\n",
        "    features.extend([np.mean(zcr), np.std(zcr), np.max(zcr)])\n",
        "\n",
        "    # Energy features\n",
        "    energy = np.sum(audio**2) / len(audio)\n",
        "    features.append(energy)\n",
        "\n",
        "    # RMS energy\n",
        "    rms = librosa.feature.rms(y=audio)[0]\n",
        "    features.extend([np.mean(rms), np.std(rms)])\n",
        "\n",
        "    # Spectral features\n",
        "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    features.extend([np.mean(spectral_centroids), np.std(spectral_centroids)])\n",
        "\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    features.extend([np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
        "\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    features.extend([np.mean(spectral_bandwidth), np.std(spectral_bandwidth)])\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "def extract_whisper_features_multilayer(audio, sampling_rate=16000):\n",
        "    \"\"\"\n",
        "    Extract Whisper features with multi-layer and multi-pooling strategy\n",
        "    CHANGED: Now handles variable-length audio without padding\n",
        "\n",
        "    Args:\n",
        "        audio: Audio waveform (actual content only, no padding)\n",
        "        sampling_rate: Sampling rate\n",
        "\n",
        "    Returns:\n",
        "        features: Concatenated feature vector\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Preprocess audio for Whisper\n",
        "        inputs = processor(\n",
        "            audio,\n",
        "            sampling_rate=sampling_rate,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Move to device\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Extract features with all hidden states\n",
        "        with torch.no_grad():\n",
        "            outputs = whisper_model.encoder(**inputs, output_hidden_states=True)\n",
        "\n",
        "        all_features = []\n",
        "\n",
        "        # Extract from multiple layers\n",
        "        if config.USE_MULTI_LAYER:\n",
        "            layers_to_process = config.LAYERS_TO_USE\n",
        "        else:\n",
        "            layers_to_process = [-1]  # Only last layer\n",
        "\n",
        "        for layer_idx in layers_to_process:\n",
        "            hidden_state = outputs.hidden_states[layer_idx]  # Shape: [batch, time, hidden]\n",
        "\n",
        "            # Apply multiple pooling strategies\n",
        "            if config.USE_MULTI_POOLING:\n",
        "                pooling_methods = config.POOLING_STRATEGIES\n",
        "            else:\n",
        "                pooling_methods = ['mean']  # Only mean pooling\n",
        "\n",
        "            for pool_strategy in pooling_methods:\n",
        "                if pool_strategy == 'mean':\n",
        "                    pooled = hidden_state.mean(dim=1)\n",
        "                elif pool_strategy == 'max':\n",
        "                    pooled = hidden_state.max(dim=1)[0]\n",
        "                elif pool_strategy == 'std':\n",
        "                    pooled = hidden_state.std(dim=1)\n",
        "                elif pool_strategy == 'min':\n",
        "                    pooled = hidden_state.min(dim=1)[0]\n",
        "                else:\n",
        "                    pooled = hidden_state.mean(dim=1)\n",
        "\n",
        "                all_features.append(pooled.cpu().numpy().squeeze())\n",
        "\n",
        "        # Concatenate all features\n",
        "        combined_features = np.concatenate(all_features)\n",
        "\n",
        "        return combined_features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö† Feature extraction error: {str(e)}\")\n",
        "        # Return zero features as fallback\n",
        "        n_layers = len(config.LAYERS_TO_USE) if config.USE_MULTI_LAYER else 1\n",
        "        n_pooling = len(config.POOLING_STRATEGIES) if config.USE_MULTI_POOLING else 1\n",
        "        feature_dim = whisper_model.config.d_model * n_layers * n_pooling\n",
        "        return np.zeros(feature_dim)\n",
        "\n",
        "print(\"‚úÖ Audio processing functions defined!\")\n",
        "print(f\"  Enhanced audio loading (NO PADDING): ‚úì\")\n",
        "print(f\"  Statistical features ({20} features): ‚úì\")\n",
        "print(f\"  Multi-layer Whisper extraction: ‚úì\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8QW6j39-4Ti",
        "outputId": "3546b63f-cf9e-46d8-e1e2-017f538519a0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[3/9] DEFINING ENHANCED AUDIO PROCESSING (NO PADDING)\n",
            "================================================================================\n",
            "‚úÖ Audio processing functions defined!\n",
            "  Enhanced audio loading (NO PADDING): ‚úì\n",
            "  Statistical features (20 features): ‚úì\n",
            "  Multi-layer Whisper extraction: ‚úì\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 7: EXTRACT FEATURES FROM ALL AUDIO FILES (NO PADDING VERSION)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[4/9] EXTRACTING FEATURES (NO PADDING - ACTUAL AUDIO ONLY)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Layers: {len(config.LAYERS_TO_USE)}\")\n",
        "print(f\"  Pooling strategies: {len(config.POOLING_STRATEGIES)}\")\n",
        "print(f\"  Statistical features: {config.USE_STATISTICAL_FEATURES}\")\n",
        "print(f\"  Feature multiplication factor: {len(config.LAYERS_TO_USE) * len(config.POOLING_STRATEGIES)}x\")\n",
        "print(f\"  Max audio length: {config.MAX_AUDIO_LENGTH_SEC}s (NO PADDING BEYOND ACTUAL CONTENT)\")\n",
        "\n",
        "def extract_features_for_dataset(df, dataset_path, audio_types, desc=\"Processing\"):\n",
        "    \"\"\"\n",
        "    Extract enhanced features for entire dataset\n",
        "    CHANGED: Now processes only actual audio content without padding\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with patient IDs and labels\n",
        "        dataset_path: Path to audio files\n",
        "        audio_types: List of audio types\n",
        "        desc: Progress bar description\n",
        "\n",
        "    Returns:\n",
        "        X: Feature matrix\n",
        "        y: Labels\n",
        "        ids: Patient IDs\n",
        "    \"\"\"\n",
        "    features_list = []\n",
        "    labels_list = []\n",
        "    ids_list = []\n",
        "\n",
        "    print(f\"\\nüéµ {desc} {len(df)} patients...\")\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=desc):\n",
        "        patient_id = row['ID']\n",
        "        patient_class = row['Class']\n",
        "\n",
        "        patient_features = []\n",
        "\n",
        "        # Process each audio type\n",
        "        for audio_type in audio_types:\n",
        "            audio_file = f\"{patient_id}_{audio_type}.wav\"\n",
        "            audio_path = os.path.join(dataset_path, audio_type, audio_file)\n",
        "\n",
        "            if os.path.exists(audio_path):\n",
        "                # CHANGED: Load audio with NO padding (actual content only)\n",
        "                audio, sr = load_audio_enhanced(\n",
        "                    audio_path,\n",
        "                    target_sr=config.SAMPLING_RATE,\n",
        "                    max_length=config.MAX_AUDIO_LENGTH\n",
        "                )\n",
        "\n",
        "                # Extract Whisper features from actual audio\n",
        "                whisper_features = extract_whisper_features_multilayer(audio, sr)\n",
        "\n",
        "                # Extract statistical features if enabled\n",
        "                if config.USE_STATISTICAL_FEATURES:\n",
        "                    stat_features = extract_statistical_features(audio, sr)\n",
        "                    combined_features = np.concatenate([whisper_features, stat_features])\n",
        "                else:\n",
        "                    combined_features = whisper_features\n",
        "\n",
        "                patient_features.append(combined_features)\n",
        "            else:\n",
        "                # Zero features for missing files\n",
        "                n_layers = len(config.LAYERS_TO_USE) if config.USE_MULTI_LAYER else 1\n",
        "                n_pooling = len(config.POOLING_STRATEGIES) if config.USE_MULTI_POOLING else 1\n",
        "                feature_dim = whisper_model.config.d_model * n_layers * n_pooling\n",
        "\n",
        "                if config.USE_STATISTICAL_FEATURES:\n",
        "                    feature_dim += 20  # Statistical features count\n",
        "\n",
        "                patient_features.append(np.zeros(feature_dim))\n",
        "\n",
        "        # Concatenate features from all audio types\n",
        "        combined = np.concatenate(patient_features)\n",
        "        features_list.append(combined)\n",
        "        labels_list.append(patient_class)\n",
        "        ids_list.append(patient_id)\n",
        "\n",
        "    X = np.array(features_list)\n",
        "    y = np.array(labels_list)\n",
        "    ids = np.array(ids_list)\n",
        "\n",
        "    return X, y, ids\n",
        "\n",
        "# Extract training features\n",
        "X_train, y_train, ids_train = extract_features_for_dataset(\n",
        "    df_train,\n",
        "    config.TRAINING_PATH,\n",
        "    config.AUDIO_TYPES,\n",
        "    desc=\"Training\"\n",
        ")\n",
        "\n",
        "# Extract validation features\n",
        "X_val, y_val, ids_val = extract_features_for_dataset(\n",
        "    df_val,\n",
        "    config.TRAINING_PATH,\n",
        "    config.AUDIO_TYPES,\n",
        "    desc=\"Validation\"\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Feature extraction complete!\")\n",
        "print(f\"  Training shape: {X_train.shape}\")\n",
        "print(f\"  Validation shape: {X_val.shape}\")\n",
        "print(f\"  Feature dimension per patient: {X_train.shape[1]}\")\n",
        "\n",
        "# Clean data (handle any NaN/Inf)\n",
        "X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_val = np.nan_to_num(X_val, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "print(f\"  Data cleaned: ‚úì\")\n",
        "\n",
        "# Save raw features\n",
        "features_path = os.path.join(config.OUTPUT_PATH, 'features_raw_no_padding.npz')\n",
        "np.savez(\n",
        "    features_path,\n",
        "    X_train=X_train, y_train=y_train, ids_train=ids_train,\n",
        "    X_val=X_val, y_val=y_val, ids_val=ids_val\n",
        ")\n",
        "print(f\"  üíæ Raw features saved: {features_path}\")\n",
        "\n",
        "# Clear GPU memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "60846c0d70a547abacac065f5eaf748e",
            "706ce753b6d240fc91b6ac52f188792a",
            "4677c28f167a4d03bea46ef857282b61",
            "899aded9ff9243dd88ab8b9e04d453a6",
            "d448decd1d234f3aa03e029d7feb9399",
            "5520f44d77b64e6da82df27a2ff384f0",
            "1f65715e9e5440e2a494522ef56e17da",
            "40e0c15eef1b4d5ba0bb248d4fa2efb8",
            "cd78fc2336314419beddd530ec77a316",
            "e5c8f8e3956c43459d09031233f0cc8f",
            "c1c6270834734029a76786de82c33bb8",
            "f3530fbb4a444923845baa0147c3ea7f",
            "7d56a6a60aa54c0eb780a726fbf84c96",
            "04ae530d4bca461891682b4f955e01ab",
            "da713abbb35941c69cd1a75ed1128791",
            "15ee67273c574214b5573e74aed2b1e0",
            "7fddeb43f1114f62a41c715d7a19e033",
            "9502b6815aa94dd7a5e085009a400558",
            "a7587e925c094c26a3b54bdae1961b72",
            "7e14a89049534eb29950a8aaf5fd0c76",
            "aab855d957c34b579ba6ed9825dc7016",
            "03f06e8744d84ae4ae4107b6bc36b210"
          ]
        },
        "id": "V9_tdmq7-6LD",
        "outputId": "886d8703-b74f-46f3-d14d-703fc9e66acd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[4/9] EXTRACTING FEATURES (NO PADDING - ACTUAL AUDIO ONLY)\n",
            "================================================================================\n",
            "Configuration:\n",
            "  Layers: 4\n",
            "  Pooling strategies: 4\n",
            "  Statistical features: True\n",
            "  Feature multiplication factor: 16x\n",
            "  Max audio length: 17s (NO PADDING BEYOND ACTUAL CONTENT)\n",
            "\n",
            "üéµ Training 219 patients...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/219 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60846c0d70a547abacac065f5eaf748e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéµ Validation 53 patients...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation:   0%|          | 0/53 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3530fbb4a444923845baa0147c3ea7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Feature extraction complete!\n",
            "  Training shape: (219, 65696)\n",
            "  Validation shape: (53, 65696)\n",
            "  Feature dimension per patient: 65696\n",
            "  Data cleaned: ‚úì\n",
            "  üíæ Raw features saved: /content/drive/MyDrive/SAND_Project_Data/optimized_whisper_rf_v2/features_raw_no_padding.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 8: ADVANCED PREPROCESSING PIPELINE\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[5/9] ADVANCED PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Step 1: Scaling\n",
        "if config.USE_ROBUST_SCALING:\n",
        "    print(\"üìä Applying RobustScaler (better for outliers)...\")\n",
        "    scaler = RobustScaler()\n",
        "else:\n",
        "    print(\"üìä Applying StandardScaler...\")\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "print(f\"  ‚úÖ Scaling complete\")\n",
        "print(f\"     Train: mean={X_train_scaled.mean():.6f}, std={X_train_scaled.std():.6f}\")\n",
        "print(f\"     Val:   mean={X_val_scaled.mean():.6f}, std={X_val_scaled.std():.6f}\")\n",
        "\n",
        "# Step 2: PCA (Dimensionality Reduction)\n",
        "if config.USE_PCA:\n",
        "    print(f\"\\nüìâ Applying PCA (variance threshold={config.PCA_VARIANCE})...\")\n",
        "    pca = PCA(n_components=config.PCA_VARIANCE, random_state=config.RANDOM_SEED)\n",
        "    X_train_scaled = pca.fit_transform(X_train_scaled)\n",
        "    X_val_scaled = pca.transform(X_val_scaled)\n",
        "\n",
        "    explained_var = pca.explained_variance_ratio_.sum()\n",
        "    print(f\"  ‚úÖ PCA complete\")\n",
        "    print(f\"     Original dimensions: {X_train.shape[1]}\")\n",
        "    print(f\"     Reduced dimensions: {X_train_scaled.shape[1]}\")\n",
        "    print(f\"     Explained variance: {explained_var*100:.2f}%\")\n",
        "    print(f\"     Dimensionality reduction: {X_train.shape[1]/X_train_scaled.shape[1]:.1f}x\")\n",
        "else:\n",
        "    pca = None\n",
        "    print(\"  ‚Ñπ PCA disabled\")\n",
        "\n",
        "# Step 3: SMOTE (Handle Class Imbalance)\n",
        "if config.USE_SMOTE:\n",
        "    print(f\"\\n‚öñÔ∏è Applying SMOTE (strategy='{config.SMOTE_STRATEGY}')...\")\n",
        "    print(f\"  Original class distribution:\")\n",
        "    unique, counts = np.unique(y_train, return_counts=True)\n",
        "    for cls, count in zip(unique, counts):\n",
        "        print(f\"    Class {cls}: {count:3d}\")\n",
        "\n",
        "    try:\n",
        "        smote = SMOTE(\n",
        "            sampling_strategy=config.SMOTE_STRATEGY,\n",
        "            k_neighbors=config.SMOTE_K_NEIGHBORS,\n",
        "            random_state=config.RANDOM_SEED\n",
        "        )\n",
        "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "        print(f\"\\n  ‚úÖ SMOTE complete\")\n",
        "        print(f\"     Samples: {len(y_train)} ‚Üí {len(y_train_resampled)}\")\n",
        "        print(f\"  Resampled class distribution:\")\n",
        "        unique, counts = np.unique(y_train_resampled, return_counts=True)\n",
        "        for cls, count in zip(unique, counts):\n",
        "            print(f\"    Class {cls}: {count:3d}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö† SMOTE failed: {e}\")\n",
        "        print(f\"  Continuing without SMOTE...\")\n",
        "        X_train_resampled = X_train_scaled\n",
        "        y_train_resampled = y_train\n",
        "else:\n",
        "    X_train_resampled = X_train_scaled\n",
        "    y_train_resampled = y_train\n",
        "    print(\"  ‚Ñπ SMOTE disabled\")\n",
        "\n",
        "print(\"\\n‚úÖ Preprocessing pipeline complete!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uukaDcc1_dPt",
        "outputId": "c6ba5a5e-4c07-449e-f28e-48981e62ac45"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[5/9] ADVANCED PREPROCESSING\n",
            "================================================================================\n",
            "üìä Applying RobustScaler (better for outliers)...\n",
            "  ‚úÖ Scaling complete\n",
            "     Train: mean=0.008359, std=0.784949\n",
            "     Val:   mean=0.007654, std=0.856875\n",
            "\n",
            "üìâ Applying PCA (variance threshold=0.97)...\n",
            "  ‚úÖ PCA complete\n",
            "     Original dimensions: 65696\n",
            "     Reduced dimensions: 190\n",
            "     Explained variance: 97.00%\n",
            "     Dimensionality reduction: 345.8x\n",
            "\n",
            "‚öñÔ∏è Applying SMOTE (strategy='not majority')...\n",
            "  Original class distribution:\n",
            "    Class 0:   4\n",
            "    Class 1:  22\n",
            "    Class 2:  45\n",
            "    Class 3:  62\n",
            "    Class 4:  86\n",
            "\n",
            "  ‚úÖ SMOTE complete\n",
            "     Samples: 219 ‚Üí 430\n",
            "  Resampled class distribution:\n",
            "    Class 0:  86\n",
            "    Class 1:  86\n",
            "    Class 2:  86\n",
            "    Class 3:  86\n",
            "    Class 4:  86\n",
            "\n",
            "‚úÖ Preprocessing pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 9: TRAIN OPTIMIZED RANDOM FOREST CLASSIFIER\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[6/9] TRAINING OPTIMIZED RANDOM FOREST\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Configuration:\")\n",
        "for key, value in config.RF_CONFIG.items():\n",
        "    if key != 'n_jobs':  # Don't print n_jobs as it's -1\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nüéØ Training Random Forest on {len(y_train_resampled)} samples...\")\n",
        "\n",
        "classifier = RandomForestClassifier(**config.RF_CONFIG)\n",
        "classifier.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(f\"‚úÖ Random Forest training complete!\")\n",
        "print(f\"  Number of trees: {classifier.n_estimators}\")\n",
        "print(f\"  Feature importance sum: {classifier.feature_importances_.sum():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUg2KvGg_k0B",
        "outputId": "7988e391-6316-4aa0-a311-2bfc7e7e0fbc"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[6/9] TRAINING OPTIMIZED RANDOM FOREST\n",
            "================================================================================\n",
            "Configuration:\n",
            "  n_estimators: 500\n",
            "  max_depth: 20\n",
            "  min_samples_split: 2\n",
            "  min_samples_leaf: 1\n",
            "  max_features: sqrt\n",
            "  bootstrap: True\n",
            "  class_weight: balanced\n",
            "  random_state: 42\n",
            "\n",
            "üéØ Training Random Forest on 430 samples...\n",
            "‚úÖ Random Forest training complete!\n",
            "  Number of trees: 500\n",
            "  Feature importance sum: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 10: CROSS-VALIDATION ON TRAINING SET\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[7/9] CROSS-VALIDATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Performing {config.N_FOLDS}-fold stratified cross-validation...\")\n",
        "print(\"‚è± This may take a few minutes...\")\n",
        "\n",
        "# Cross-validation on ORIGINAL training set (before SMOTE)\n",
        "cv_classifier = RandomForestClassifier(**config.RF_CONFIG)\n",
        "cv_scores = cross_val_score(\n",
        "    cv_classifier,\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    cv=config.N_FOLDS,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Cross-validation complete!\")\n",
        "print(f\"  Fold scores: {[f'{s:.4f}' for s in cv_scores]}\")\n",
        "print(f\"  Mean CV F1: {cv_scores.mean():.4f}\")\n",
        "print(f\"  Std CV F1:  {cv_scores.std():.4f}\")\n",
        "print(f\"  Min CV F1:  {cv_scores.min():.4f}\")\n",
        "print(f\"  Max CV F1:  {cv_scores.max():.4f}\")\n",
        "\n",
        "# Detailed k-fold cross-validation metrics\n",
        "print(f\"\\nüìä DETAILED {config.N_FOLDS}-FOLD CROSS-VALIDATION METRICS:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Perform detailed cross-validation with multiple metrics\n",
        "kfold = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.RANDOM_SEED)\n",
        "\n",
        "cv_accuracy_scores = []\n",
        "cv_f1_scores = []\n",
        "cv_precision_scores = []\n",
        "cv_recall_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_scaled, y_train), 1):\n",
        "    X_fold_train, X_fold_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    # Train on fold\n",
        "    fold_classifier = RandomForestClassifier(**config.RF_CONFIG)\n",
        "    fold_classifier.fit(X_fold_train, y_fold_train)\n",
        "\n",
        "    # Predict on validation fold\n",
        "    y_fold_pred = fold_classifier.predict(X_fold_val)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_fold_val, y_fold_pred)\n",
        "    f1 = f1_score(y_fold_val, y_fold_pred, average='macro')\n",
        "    precision = precision_score(y_fold_val, y_fold_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_fold_val, y_fold_pred, average='macro', zero_division=0)\n",
        "\n",
        "    cv_accuracy_scores.append(accuracy)\n",
        "    cv_f1_scores.append(f1)\n",
        "    cv_precision_scores.append(precision)\n",
        "    cv_recall_scores.append(recall)\n",
        "\n",
        "    print(f\"Fold {fold}:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  F1 Score:  {f1:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  Samples:   Train={len(y_fold_train)}, Val={len(y_fold_val)}\")\n",
        "    print()\n",
        "\n",
        "print(\"üìà CROSS-VALIDATION SUMMARY:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {np.mean(cv_accuracy_scores):.4f} ¬± {np.std(cv_accuracy_scores):.4f}\")\n",
        "print(f\"F1 Score:  {np.mean(cv_f1_scores):.4f} ¬± {np.std(cv_f1_scores):.4f}\")\n",
        "print(f\"Precision: {np.mean(cv_precision_scores):.4f} ¬± {np.std(cv_precision_scores):.4f}\")\n",
        "print(f\"Recall:    {np.mean(cv_recall_scores):.4f} ¬± {np.std(cv_recall_scores):.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzAJh8Tt_mR9",
        "outputId": "7aacca09-af33-47ee-ad13-8857187742e2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[7/9] CROSS-VALIDATION\n",
            "================================================================================\n",
            "Performing 5-fold stratified cross-validation...\n",
            "‚è± This may take a few minutes...\n",
            "\n",
            "‚úÖ Cross-validation complete!\n",
            "  Fold scores: ['0.1115', '0.1133', '0.1115', '0.1637', '0.1417']\n",
            "  Mean CV F1: 0.1283\n",
            "  Std CV F1:  0.0211\n",
            "  Min CV F1:  0.1115\n",
            "  Max CV F1:  0.1637\n",
            "\n",
            "üìä DETAILED 5-FOLD CROSS-VALIDATION METRICS:\n",
            "==================================================\n",
            "Fold 1:\n",
            "  Accuracy:  0.4091\n",
            "  F1 Score:  0.1161\n",
            "  Precision: 0.0818\n",
            "  Recall:    0.2000\n",
            "  Samples:   Train=175, Val=44\n",
            "\n",
            "Fold 2:\n",
            "  Accuracy:  0.3864\n",
            "  F1 Score:  0.1115\n",
            "  Precision: 0.0773\n",
            "  Recall:    0.2000\n",
            "  Samples:   Train=175, Val=44\n",
            "\n",
            "Fold 3:\n",
            "  Accuracy:  0.3864\n",
            "  F1 Score:  0.1115\n",
            "  Precision: 0.0773\n",
            "  Recall:    0.2000\n",
            "  Samples:   Train=175, Val=44\n",
            "\n",
            "Fold 4:\n",
            "  Accuracy:  0.3864\n",
            "  F1 Score:  0.1115\n",
            "  Precision: 0.0773\n",
            "  Recall:    0.2000\n",
            "  Samples:   Train=175, Val=44\n",
            "\n",
            "Fold 5:\n",
            "  Accuracy:  0.3721\n",
            "  F1 Score:  0.1404\n",
            "  Precision: 0.1000\n",
            "  Recall:    0.2353\n",
            "  Samples:   Train=176, Val=43\n",
            "\n",
            "üìà CROSS-VALIDATION SUMMARY:\n",
            "==================================================\n",
            "Accuracy:  0.3881 ¬± 0.0119\n",
            "F1 Score:  0.1182 ¬± 0.0112\n",
            "Precision: 0.0827 ¬± 0.0088\n",
            "Recall:    0.2071 ¬± 0.0141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 11: EVALUATE ON TRAINING AND VALIDATION SETS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[8/9] MODEL EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# 1. TRAINING SET EVALUATION (Check for overfitting)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä TRAINING SET EVALUATION (Overfitting Check)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Predict on training set\n",
        "y_train_pred = classifier.predict(X_train_resampled)\n",
        "y_train_pred_proba = classifier.predict_proba(X_train_resampled)\n",
        "\n",
        "# Compute training metrics\n",
        "train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
        "train_f1_macro = f1_score(y_train_resampled, y_train_pred, average='macro')\n",
        "train_f1_weighted = f1_score(y_train_resampled, y_train_pred, average='weighted')\n",
        "train_precision = precision_score(y_train_resampled, y_train_pred, average='macro', zero_division=0)\n",
        "train_recall = recall_score(y_train_resampled, y_train_pred, average='macro', zero_division=0)\n",
        "train_kappa = cohen_kappa_score(y_train_resampled, y_train_pred)\n",
        "train_f1_per_class = f1_score(y_train_resampled, y_train_pred, average=None, zero_division=0)\n",
        "\n",
        "print(f\"Training Accuracy:      {train_accuracy:.4f}\")\n",
        "print(f\"Training F1 (Macro):    {train_f1_macro:.4f}\")\n",
        "print(f\"Training F1 (Weighted): {train_f1_weighted:.4f}\")\n",
        "print(f\"Training Precision:     {train_precision:.4f}\")\n",
        "print(f\"Training Recall:        {train_recall:.4f}\")\n",
        "print(f\"Training Kappa:         {train_kappa:.4f}\")\n",
        "\n",
        "# Training set classification report\n",
        "print(\"\\n\" + \"-\"*80)\n",
        "print(\"TRAINING CLASSIFICATION REPORT:\")\n",
        "print(\"-\"*80)\n",
        "available_classes_train = sorted(np.unique(y_train_resampled))\n",
        "class_labels_train = [config.CLASS_NAMES[i] for i in available_classes_train]\n",
        "print(classification_report(y_train_resampled, y_train_pred, target_names=class_labels_train, zero_division=0))\n",
        "\n",
        "# Training confusion matrix\n",
        "train_cm = confusion_matrix(y_train_resampled, y_train_pred)\n",
        "print(\"\\nTRAINING CONFUSION MATRIX:\")\n",
        "print(train_cm)\n",
        "\n",
        "# ============================================================================\n",
        "# 2. VALIDATION SET EVALUATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä VALIDATION SET EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Predict on validation set\n",
        "y_val_pred = classifier.predict(X_val_scaled)\n",
        "y_val_pred_proba = classifier.predict_proba(X_val_scaled)\n",
        "\n",
        "# Compute validation metrics\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "f1_macro = f1_score(y_val, y_val_pred, average='macro')\n",
        "f1_weighted = f1_score(y_val, y_val_pred, average='weighted')\n",
        "precision = precision_score(y_val, y_val_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_val, y_val_pred, average='macro', zero_division=0)\n",
        "kappa = cohen_kappa_score(y_val, y_val_pred)\n",
        "f1_per_class = f1_score(y_val, y_val_pred, average=None, zero_division=0)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ FINAL RESULTS - OPTIMIZED WHISPER + RANDOM FOREST (NO PADDING)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Validation Accuracy:      {accuracy:.4f}\")\n",
        "print(f\"F1 Score (Macro):         {f1_macro:.4f} \")\n",
        "print(f\"F1 Score (Weighted):      {f1_weighted:.4f}\")\n",
        "print(f\"Precision (Macro):        {precision:.4f}\")\n",
        "print(f\"Recall (Macro):           {recall:.4f}\")\n",
        "print(f\"Cohen's Kappa:            {kappa:.4f}\")\n",
        "print(f\"CV F1 (Mean ¬± Std):       {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# 3. OVERFITTING ANALYSIS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîç OVERFITTING ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate performance gaps\n",
        "accuracy_gap = train_accuracy - accuracy\n",
        "f1_gap = train_f1_macro - f1_macro\n",
        "precision_gap = train_precision - precision\n",
        "recall_gap = train_recall - recall\n",
        "\n",
        "print(f\"Performance Gaps (Training - Validation):\")\n",
        "print(f\"  Accuracy:  {train_accuracy:.4f} - {accuracy:.4f} = {accuracy_gap:+.4f}\")\n",
        "print(f\"  F1 Score:  {train_f1_macro:.4f} - {f1_macro:.4f} = {f1_gap:+.4f}\")\n",
        "print(f\"  Precision: {train_precision:.4f} - {precision:.4f} = {precision_gap:+.4f}\")\n",
        "print(f\"  Recall:    {train_recall:.4f} - {recall:.4f} = {recall_gap:+.4f}\")\n",
        "\n",
        "# Overfitting assessment\n",
        "if f1_gap > 0.15:\n",
        "    print(f\"\\n‚ö†Ô∏è SIGNIFICANT OVERFITTING DETECTED!\")\n",
        "    print(f\"   F1 gap: {f1_gap:.4f} > 0.15\")\n",
        "elif f1_gap > 0.10:\n",
        "    print(f\"\\nüìà MODERATE OVERFITTING DETECTED\")\n",
        "    print(f\"   F1 gap: {f1_gap:.4f} > 0.10\")\n",
        "elif f1_gap > 0.05:\n",
        "    print(f\"\\nüìä SLIGHT OVERFITTING DETECTED\")\n",
        "    print(f\"   F1 gap: {f1_gap:.4f} > 0.05\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ GOOD GENERALIZATION!\")\n",
        "    print(f\"   F1 gap: {f1_gap:.4f} ‚â§ 0.05\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. PER-CLASS PERFORMANCE (Validation)\n",
        "# ============================================================================\n",
        "print(\"\\nüìä PER-CLASS PERFORMANCE (Validation):\")\n",
        "available_classes = sorted(np.unique(y_val))\n",
        "for cls, f1_val in zip(available_classes, [f1_per_class[i] for i in available_classes]):\n",
        "    label = config.CLASS_NAMES[cls]\n",
        "    bar = '‚ñà' * int(f1_val * 40)\n",
        "    print(f\"  Class {cls} ({label:25s}): {f1_val:.4f} {bar}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n\" + \"-\"*80)\n",
        "print(\"CLASSIFICATION REPORT (Validation):\")\n",
        "print(\"-\"*80)\n",
        "class_labels = [config.CLASS_NAMES[i] for i in available_classes]\n",
        "print(classification_report(y_val, y_val_pred, target_names=class_labels, zero_division=0))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_val, y_val_pred)\n",
        "print(\"\\nCONFUSION MATRIX (Validation):\")\n",
        "print(cm)\n",
        "\n",
        "# ============================================================================\n",
        "# 5. ACHIEVEMENT STATUS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "baseline_f1 = 0.4919\n",
        "target_f1 = 0.70\n",
        "improvement = f1_macro - baseline_f1\n",
        "\n",
        "if f1_macro >= target_f1:\n",
        "    print(f\"üéâüéâüéâ TARGET ACHIEVED! üéâüéâüéâ\")\n",
        "    print(f\"F1 Score: {f1_macro:.4f} >= {target_f1:.4f}\")\n",
        "    print(f\"Improvement over baseline: +{improvement:.4f} (+{improvement/baseline_f1*100:.1f}%)\")\n",
        "elif f1_macro >= 0.65:\n",
        "    print(f\"üöÄ EXCELLENT PROGRESS!\")\n",
        "    print(f\"F1 Score: {f1_macro:.4f}\")\n",
        "    print(f\"Gap to target: -{target_f1 - f1_macro:.4f}\")\n",
        "    print(f\"Improvement over baseline: +{improvement:.4f} (+{improvement/baseline_f1*100:.1f}%)\")\n",
        "else:\n",
        "    print(f\"üìà STRONG IMPROVEMENT!\")\n",
        "    print(f\"F1 Score: {f1_macro:.4f}\")\n",
        "    print(f\"Improvement over baseline: +{improvement:.4f} (+{improvement/baseline_f1*100:.1f}%)\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsRp8d6QEjdr",
        "outputId": "a2694022-fff3-4385-979a-b9c43665b44e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[8/9] MODEL EVALUATION\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìä TRAINING SET EVALUATION (Overfitting Check)\n",
            "================================================================================\n",
            "Training Accuracy:      0.9977\n",
            "Training F1 (Macro):    0.9977\n",
            "Training F1 (Weighted): 0.9977\n",
            "Training Precision:     0.9977\n",
            "Training Recall:        0.9977\n",
            "Training Kappa:         0.9971\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "TRAINING CLASSIFICATION REPORT:\n",
            "--------------------------------------------------------------------------------\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  Severe Dysarthria       1.00      1.00      1.00        86\n",
            "Moderate Dysarthria       1.00      1.00      1.00        86\n",
            "    Mild Dysarthria       1.00      1.00      1.00        86\n",
            "No Dysarthria (ALS)       0.99      1.00      0.99        86\n",
            "            Healthy       1.00      0.99      0.99        86\n",
            "\n",
            "           accuracy                           1.00       430\n",
            "          macro avg       1.00      1.00      1.00       430\n",
            "       weighted avg       1.00      1.00      1.00       430\n",
            "\n",
            "\n",
            "TRAINING CONFUSION MATRIX:\n",
            "[[86  0  0  0  0]\n",
            " [ 0 86  0  0  0]\n",
            " [ 0  0 86  0  0]\n",
            " [ 0  0  0 86  0]\n",
            " [ 0  0  0  1 85]]\n",
            "\n",
            "================================================================================\n",
            "üìä VALIDATION SET EVALUATION\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üéØ FINAL RESULTS - OPTIMIZED WHISPER + RANDOM FOREST (NO PADDING)\n",
            "================================================================================\n",
            "Validation Accuracy:      0.5660\n",
            "F1 Score (Macro):         0.4834 \n",
            "F1 Score (Weighted):      0.5475\n",
            "Precision (Macro):        0.4526\n",
            "Recall (Macro):           0.5452\n",
            "Cohen's Kappa:            0.4068\n",
            "CV F1 (Mean ¬± Std):       0.1283 ¬± 0.0211\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üîç OVERFITTING ANALYSIS\n",
            "================================================================================\n",
            "Performance Gaps (Training - Validation):\n",
            "  Accuracy:  0.9977 - 0.5660 = +0.4316\n",
            "  F1 Score:  0.9977 - 0.4834 = +0.5142\n",
            "  Precision: 0.9977 - 0.4526 = +0.5451\n",
            "  Recall:    0.9977 - 0.5452 = +0.4524\n",
            "\n",
            "‚ö†Ô∏è SIGNIFICANT OVERFITTING DETECTED!\n",
            "   F1 gap: 0.5142 > 0.15\n",
            "\n",
            "üìä PER-CLASS PERFORMANCE (Validation):\n",
            "  Class 0 (Severe Dysarthria        ): 0.0000 \n",
            "  Class 1 (Moderate Dysarthria      ): 0.7273 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  Class 2 (Mild Dysarthria          ): 0.6667 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  Class 3 (No Dysarthria (ALS)      ): 0.4828 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  Class 4 (Healthy                  ): 0.5405 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "CLASSIFICATION REPORT (Validation):\n",
            "--------------------------------------------------------------------------------\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  Severe Dysarthria       0.00      0.00      0.00         2\n",
            "Moderate Dysarthria       0.57      1.00      0.73         4\n",
            "    Mild Dysarthria       0.60      0.75      0.67        12\n",
            "No Dysarthria (ALS)       0.47      0.50      0.48        14\n",
            "            Healthy       0.62      0.48      0.54        21\n",
            "\n",
            "           accuracy                           0.57        53\n",
            "          macro avg       0.45      0.55      0.48        53\n",
            "       weighted avg       0.55      0.57      0.55        53\n",
            "\n",
            "\n",
            "CONFUSION MATRIX (Validation):\n",
            "[[ 0  2  0  0  0]\n",
            " [ 0  4  0  0  0]\n",
            " [ 0  0  9  2  1]\n",
            " [ 0  0  2  7  5]\n",
            " [ 0  1  4  6 10]]\n",
            "\n",
            "================================================================================\n",
            "üìà STRONG IMPROVEMENT!\n",
            "F1 Score: 0.4834\n",
            "Improvement over baseline: +-0.0085 (+-1.7%)\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 12: SAVE MODEL AND RESULTS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[9/9] SAVING MODEL AND RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save model\n",
        "model_path = os.path.join(config.OUTPUT_PATH, 'random_forest_model_no_padding.joblib')\n",
        "joblib.dump(classifier, model_path)\n",
        "print(f\"‚úÖ Model saved: {model_path}\")\n",
        "\n",
        "# Save scaler\n",
        "scaler_path = os.path.join(config.OUTPUT_PATH, 'scaler_no_padding.joblib')\n",
        "joblib.dump(scaler, scaler_path)\n",
        "print(f\"‚úÖ Scaler saved: {scaler_path}\")\n",
        "\n",
        "# Save PCA\n",
        "if pca is not None:\n",
        "    pca_path = os.path.join(config.OUTPUT_PATH, 'pca_no_padding.joblib')\n",
        "    joblib.dump(pca, pca_path)\n",
        "    print(f\"‚úÖ PCA saved: {pca_path}\")\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'model': 'Random Forest',\n",
        "    'feature_extractor': 'Whisper (openai/whisper-base)',\n",
        "    'audio_processing': 'No padding - actual content only (max 15s)',\n",
        "    'validation_metrics': {\n",
        "        'accuracy': float(accuracy),\n",
        "        'f1_macro': float(f1_macro),\n",
        "        'f1_weighted': float(f1_weighted),\n",
        "        'precision': float(precision),\n",
        "        'recall': float(recall),\n",
        "        'kappa': float(kappa)\n",
        "    },\n",
        "    'cross_validation': {\n",
        "        'mean_f1': float(cv_scores.mean()),\n",
        "        'std_f1': float(cv_scores.std()),\n",
        "        'fold_scores': [float(s) for s in cv_scores]\n",
        "    },\n",
        "    'training_metrics': {\n",
        "        'accuracy': float(train_accuracy),\n",
        "        'f1_macro': float(train_f1_macro),\n",
        "        'precision': float(train_precision),\n",
        "        'recall': float(train_recall)\n",
        "    },\n",
        "    'overfitting_gaps': {\n",
        "        'accuracy_gap': float(accuracy_gap),\n",
        "        'f1_gap': float(f1_gap),\n",
        "        'precision_gap': float(precision_gap),\n",
        "        'recall_gap': float(recall_gap)\n",
        "    },\n",
        "    'per_class_f1': {config.CLASS_NAMES[i]: float(f1_per_class[i]) for i in available_classes},\n",
        "    'confusion_matrix': cm.tolist(),\n",
        "    'config': {\n",
        "        'max_audio_length_sec': config.MAX_AUDIO_LENGTH_SEC,\n",
        "        'use_padding': config.USE_PADDING,\n",
        "        'use_multi_layer': config.USE_MULTI_LAYER,\n",
        "        'use_multi_pooling': config.USE_MULTI_POOLING,\n",
        "        'use_statistical_features': config.USE_STATISTICAL_FEATURES,\n",
        "        'use_pca': config.USE_PCA,\n",
        "        'use_smote': config.USE_SMOTE,\n",
        "        'rf_n_estimators': config.RF_CONFIG['n_estimators']\n",
        "    }\n",
        "}\n",
        "\n",
        "results_path = os.path.join(config.OUTPUT_PATH, 'results_no_padding.json')\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print(f\"‚úÖ Results saved: {results_path}\")\n",
        "\n",
        "# Save predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'ID': ids_val,\n",
        "    'True_Class': y_val,\n",
        "    'Predicted_Class': y_val_pred,\n",
        "    'True_Label': [config.CLASS_NAMES[c] for c in y_val],\n",
        "    'Predicted_Label': [config.CLASS_NAMES[c] for c in y_val_pred],\n",
        "    'Correct': y_val == y_val_pred\n",
        "})\n",
        "\n",
        "# Add prediction probabilities\n",
        "for i in range(len(config.CLASS_NAMES)):\n",
        "    predictions_df[f'Prob_Class_{i}'] = y_val_pred_proba[:, i]\n",
        "\n",
        "predictions_path = os.path.join(config.OUTPUT_PATH, 'validation_predictions_no_padding.csv')\n",
        "predictions_df.to_csv(predictions_path, index=False)\n",
        "print(f\"‚úÖ Predictions saved: {predictions_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéä ALL TASKS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Validation F1 Score: {f1_macro:.4f}\")\n",
        "print(f\"  Validation Accuracy: {accuracy:.4f}\")\n",
        "print(f\"  CV F1 Score: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
        "print(f\"  Overfitting (F1 gap): {f1_gap:.4f}\")\n",
        "print(f\"\\nAll outputs saved to: {config.OUTPUT_PATH}\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlEACeLNxeHK",
        "outputId": "0c182edd-7668-45ef-918b-3d48dba81764"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[9/9] SAVING MODEL AND RESULTS\n",
            "================================================================================\n",
            "‚úÖ Model saved: /content/drive/MyDrive/SAND_Project_Data/optimized_whisper_rf_v2/random_forest_model_no_padding.joblib\n",
            "‚úÖ Scaler saved: /content/drive/MyDrive/SAND_Project_Data/optimized_whisper_rf_v2/scaler_no_padding.joblib\n",
            "‚úÖ PCA saved: /content/drive/MyDrive/SAND_Project_Data/optimized_whisper_rf_v2/pca_no_padding.joblib\n",
            "‚úÖ Results saved: /content/drive/MyDrive/SAND_Project_Data/optimized_whisper_rf_v2/results_no_padding.json\n",
            "‚úÖ Predictions saved: /content/drive/MyDrive/SAND_Project_Data/optimized_whisper_rf_v2/validation_predictions_no_padding.csv\n",
            "\n",
            "================================================================================\n",
            "üéä ALL TASKS COMPLETED SUCCESSFULLY!\n",
            "================================================================================\n",
            "\n",
            "Summary:\n",
            "  Validation F1 Score: 0.4834\n",
            "  Validation Accuracy: 0.5660\n",
            "  CV F1 Score: 0.1283 ¬± 0.0211\n",
            "  Overfitting (F1 gap): 0.5142\n",
            "\n",
            "All outputs saved to: /content/drive/MyDrive/SAND_Project_Data/optimized_whisper_rf_v2\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}