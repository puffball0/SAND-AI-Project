{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be4ac9cd31034e8eb733744e0fcf86e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2955e22f9114f6b85b41c054cb68320",
              "IPY_MODEL_e3027e3603184c46b30e23e76dff7e96",
              "IPY_MODEL_379a6f2bbc9248629ff8145a75e1281e"
            ],
            "layout": "IPY_MODEL_80424fe3c4174143854eb9b13c4e8539"
          }
        },
        "a2955e22f9114f6b85b41c054cb68320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a5b1b8163c4d78ad2b91cc1dbd765f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_71c1243c417f43a695c154d1069c5a5f",
            "value": "Training:â€‡100%"
          }
        },
        "e3027e3603184c46b30e23e76dff7e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7dace37dacc4abca0e2158855dd356a",
            "max": 219,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77d7c8be493642fc85be434919d13ffb",
            "value": 219
          }
        },
        "379a6f2bbc9248629ff8145a75e1281e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_176c8618ea7b42dcb934199393eb9198",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_212979d2b2d3412489980575df21f204",
            "value": "â€‡219/219â€‡[04:30&lt;00:00,â€‡â€‡1.23it/s]"
          }
        },
        "80424fe3c4174143854eb9b13c4e8539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a5b1b8163c4d78ad2b91cc1dbd765f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71c1243c417f43a695c154d1069c5a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7dace37dacc4abca0e2158855dd356a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d7c8be493642fc85be434919d13ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "176c8618ea7b42dcb934199393eb9198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "212979d2b2d3412489980575df21f204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f024775ab244ea0bf825defb8881760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fcf66ffc588411abadb8748a1244f77",
              "IPY_MODEL_799173b2973a4779a8d76db34ce2fdc9",
              "IPY_MODEL_2fa54e8b46554b2aaf9e74a8232c6977"
            ],
            "layout": "IPY_MODEL_c47a5023f9fa4284beed9283f9ed1ede"
          }
        },
        "7fcf66ffc588411abadb8748a1244f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db63e7946c314d65ab076c6c6a845428",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ee757cf26a3346bf89808f49854423c1",
            "value": "Validation:â€‡100%"
          }
        },
        "799173b2973a4779a8d76db34ce2fdc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21eaceefdd1f4c59a9fa7b0e4c64d54e",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66cdd14f1ebb45de90d7fcafe5cd90db",
            "value": 53
          }
        },
        "2fa54e8b46554b2aaf9e74a8232c6977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d78cf98c6ad4c6a88b2e1bf54b1d13c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c9ee17683380420bad517ce8a0a22f22",
            "value": "â€‡53/53â€‡[00:42&lt;00:00,â€‡â€‡1.22it/s]"
          }
        },
        "c47a5023f9fa4284beed9283f9ed1ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db63e7946c314d65ab076c6c6a845428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee757cf26a3346bf89808f49854423c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21eaceefdd1f4c59a9fa7b0e4c64d54e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66cdd14f1ebb45de90d7fcafe5cd90db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d78cf98c6ad4c6a88b2e1bf54b1d13c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9ee17683380420bad517ce8a0a22f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pTw58rRCNmUX",
        "outputId": "200a4c22-ecbe-4fc3-fd66-0c9bf3f79d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Whisper \n",
            "Random Forest Classifier \n",
            "Balanced Dataset\n",
            "================================================================================\n",
            "Mounted at /content/drive\n",
            "\n",
            "[Installing packages...]\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: SETUP AND INSTALLATION\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"Whisper \\nRandom Forest Classifier \\nBalanced Dataset\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Install required packages\n",
        "print(\"\\n[Installing packages...]\")\n",
        "!pip uninstall -y transformers huggingface_hub tokenizers -q\n",
        "!pip install transformers==4.40.0 -q\n",
        "!pip install torch torchaudio -q\n",
        "!pip install scikit-learn pandas numpy -q\n",
        "!pip install librosa soundfile -q\n",
        "!pip install imbalanced-learn -q\n",
        "!pip install matplotlib seaborn -q\n",
        "print(\"âœ… Installation complete!\")\n",
        "\n",
        "print(\"\\nðŸ”„ Restarting runtime...\")\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 2: IMPORTS (RUN AFTER RESTART)\n",
        "# ============================================================================\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Replace HuBERT with Whisper\n",
        "from transformers import WhisperModel, WhisperFeatureExtractor, WhisperProcessor\n",
        "\n",
        "# Replace SVM with Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    confusion_matrix, classification_report, cohen_kappa_score\n",
        ")\n",
        "\n",
        "# COMMENTED OUT: SMOTE imports (keeping for reference)\n",
        "# from imblearn.over_sampling import SMOTE, ADASYN\n",
        "# from imblearn.combine import SMOTETomek\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from tqdm.auto import tqdm\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Mount Drive again after restart\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "print(\"âœ… All imports successful!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kcDZu0_KNxWa",
        "outputId": "fe3a6662-ab0d-4abd-e114-e82e4264e552"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Using device: cuda\n",
            "âœ… All imports successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 3: OPTIMIZED CONFIGURATION\n",
        "# ============================================================================\n",
        "class Config:\n",
        "    \"\"\"Optimized Configuration for Maximum Performance\"\"\"\n",
        "\n",
        "    # Paths\n",
        "    BASE_PATH = '/content/drive/MyDrive/SAND_Project_Data'\n",
        "    TRAINING_PATH = os.path.join(BASE_PATH, 'training')\n",
        "    EXCEL_PATH = os.path.join(BASE_PATH, 'sand_task_1.xlsx')\n",
        "    OUTPUT_PATH = os.path.join(BASE_PATH, 'optimized_whisper_rf_v2')\n",
        "\n",
        "    # Sheet names\n",
        "    SHEET_TRAINING = 'Training Baseline - Task 1'\n",
        "    SHEET_VALIDATION = 'Validation Baseline - Task 1'\n",
        "\n",
        "    # Audio types\n",
        "    AUDIO_TYPES = ['phonationA', 'phonationE', 'phonationI', 'phonationO', 'phonationU',\n",
        "                   'rhythmKA', 'rhythmPA', 'rhythmTA']\n",
        "\n",
        "    # ========================================================================\n",
        "    # OPTIMIZED WHISPER CONFIGURATION\n",
        "    # ========================================================================\n",
        "    WHISPER_MODEL = 'openai/whisper-base'\n",
        "    SAMPLING_RATE = 16000\n",
        "    MAX_AUDIO_LENGTH_SEC = 17  # Maximum 17 seconds\n",
        "    MAX_AUDIO_LENGTH = 16000 * MAX_AUDIO_LENGTH_SEC  # 17 seconds in samples\n",
        "\n",
        "    # Multi-layer feature extraction (CRITICAL FOR PERFORMANCE)\n",
        "    USE_MULTI_LAYER = True\n",
        "    LAYERS_TO_USE = [-4, -3, -2, -1]  # Last 4 layers\n",
        "\n",
        "    # Multi-pooling strategy (CRITICAL FOR PERFORMANCE)\n",
        "    USE_MULTI_POOLING = True\n",
        "    POOLING_STRATEGIES = ['mean', 'std', 'max', 'min']  # 4 pooling methods\n",
        "\n",
        "    # Statistical features (HELPS WITH DYSARTHRIA PATTERNS)\n",
        "    USE_STATISTICAL_FEATURES = True\n",
        "\n",
        "    # Audio processing - no padding, slice to actual content only\n",
        "    AUDIO_TRIM_DB = 15  # Lower threshold for dysarthric speech\n",
        "    AUDIO_NORMALIZE = True\n",
        "    MIN_AUDIO_LENGTH_SEC = 2  # Minimum 2 seconds\n",
        "    USE_PADDING = False  # No padding beyond minimum\n",
        "\n",
        "    # ========================================================================\n",
        "    # PREPROCESSING OPTIMIZATIONS\n",
        "    # ========================================================================\n",
        "    USE_ROBUST_SCALING = True  # Better for outliers\n",
        "\n",
        "    # PCA Configuration\n",
        "    USE_PCA = True\n",
        "    PCA_VARIANCE = 0.97  # Retain 97% variance\n",
        "\n",
        "    # ========================================================================\n",
        "    # DATA BALANCING (COMMENTED OUT - TESTING UNBALANCED DATA)\n",
        "    # ========================================================================\n",
        "    # COMMENTED OUT: Testing without SMOTE on unbalanced data\n",
        "    USE_SMOTE = False  # CHANGED: Disabled SMOTE\n",
        "    # SMOTE_STRATEGY = 'not majority'  # Oversample all except majority\n",
        "    # SMOTE_K_NEIGHBORS = 2  # Lower for small classes\n",
        "\n",
        "    # ========================================================================\n",
        "    # OPTIMIZED RANDOM FOREST HYPERPARAMETERS\n",
        "    # ========================================================================\n",
        "    RF_CONFIG = {\n",
        "        'n_estimators': 500,\n",
        "        'max_depth': 20,\n",
        "        'min_samples_split': 2,\n",
        "        'min_samples_leaf': 1,\n",
        "        'max_features': 'sqrt',\n",
        "        'bootstrap': True,\n",
        "        'class_weight': 'balanced',\n",
        "        'random_state': RANDOM_SEED,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    # Cross-validation\n",
        "    N_FOLDS = 5\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "    # Class names\n",
        "    CLASS_NAMES = {\n",
        "        0: 'Severe Dysarthria',\n",
        "        1: 'Moderate Dysarthria',\n",
        "        2: 'Mild Dysarthria',\n",
        "        3: 'No Dysarthria (ALS)',\n",
        "        4: 'Healthy'\n",
        "    }\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“‹ OPTIMIZED CONFIGURATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Whisper Model: {config.WHISPER_MODEL}\")\n",
        "print(f\"Multi-Layer Extraction: {config.USE_MULTI_LAYER} ({len(config.LAYERS_TO_USE)} layers)\")\n",
        "print(f\"Multi-Pooling: {config.USE_MULTI_POOLING} ({len(config.POOLING_STRATEGIES)} strategies)\")\n",
        "print(f\"Statistical Features: {config.USE_STATISTICAL_FEATURES}\")\n",
        "print(f\"PCA: {config.USE_PCA} (variance={config.PCA_VARIANCE})\")\n",
        "print(f\"SMOTE: {config.USE_SMOTE} âš ï¸ DISABLED - TESTING UNBALANCED DATA\")\n",
        "print(f\"Random Forest Estimators: {config.RF_CONFIG['n_estimators']}\")\n",
        "print(f\"Max Audio Length: {config.MAX_AUDIO_LENGTH_SEC} seconds (NO PADDING)\")\n",
        "print(f\"Use Padding: {config.USE_PADDING}\")\n",
        "print(f\"Device: {device}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verify paths\n",
        "print(f\"\\nðŸ“‚ Verifying paths...\")\n",
        "assert os.path.exists(config.BASE_PATH), \"Base path not found!\"\n",
        "assert os.path.exists(config.TRAINING_PATH), \"Training path not found!\"\n",
        "assert os.path.exists(config.EXCEL_PATH), \"Excel file not found!\"\n",
        "print(\"âœ… All paths verified!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rvLnl0lwN5ft",
        "outputId": "00b00ca9-76e6-47f0-80b2-5df2e41754b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ðŸ“‹ OPTIMIZED CONFIGURATION\n",
            "================================================================================\n",
            "Whisper Model: openai/whisper-base\n",
            "Multi-Layer Extraction: True (4 layers)\n",
            "Multi-Pooling: True (4 strategies)\n",
            "Statistical Features: True\n",
            "PCA: True (variance=0.97)\n",
            "SMOTE: False âš ï¸ DISABLED - TESTING UNBALANCED DATA\n",
            "Random Forest Estimators: 500\n",
            "Max Audio Length: 17 seconds (NO PADDING)\n",
            "Use Padding: False\n",
            "Device: cuda\n",
            "================================================================================\n",
            "\n",
            "ðŸ“‚ Verifying paths...\n",
            "âœ… All paths verified!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 4: LOAD DATASETS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[1/9] LOADING DATASETS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def load_data(excel_path, sheet_name):\n",
        "    \"\"\"Load dataset from Excel\"\"\"\n",
        "    df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "    print(f\"\\nâœ… Loaded {len(df)} samples from: '{sheet_name}'\")\n",
        "\n",
        "    # Convert to 0-indexed classes\n",
        "    df['Class'] = df['Class'] - 1\n",
        "\n",
        "    # Display distribution\n",
        "    print(f\"ðŸ“Š Class distribution:\")\n",
        "    class_dist = df['Class'].value_counts().sort_index()\n",
        "    for cls, count in class_dist.items():\n",
        "        pct = (count / len(df)) * 100\n",
        "        print(f\"  Class {cls} ({config.CLASS_NAMES[cls]:25s}): {count:3d} ({pct:5.2f}%)\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load training and validation sets\n",
        "df_train = load_data(config.EXCEL_PATH, config.SHEET_TRAINING)\n",
        "df_val = load_data(config.EXCEL_PATH, config.SHEET_VALIDATION)\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Summary:\")\n",
        "print(f\"  Training samples: {len(df_train)}\")\n",
        "print(f\"  Validation samples: {len(df_val)}\")\n",
        "print(f\"  Total audio files: {(len(df_train) + len(df_val)) * len(config.AUDIO_TYPES)}\")\n",
        "\n",
        "# Verify no overlap\n",
        "train_ids = set(df_train['ID'].values)\n",
        "val_ids = set(df_val['ID'].values)\n",
        "overlap = train_ids.intersection(val_ids)\n",
        "print(f\"  Overlap check: {'âœ… No overlap' if len(overlap) == 0 else f'âš ï¸ {len(overlap)} overlapping IDs'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TTGjHymmN8Cx",
        "outputId": "75a81658-aad8-4087-fdae-489f748e612b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[1/9] LOADING DATASETS\n",
            "================================================================================\n",
            "\n",
            "âœ… Loaded 219 samples from: 'Training Baseline - Task 1'\n",
            "ðŸ“Š Class distribution:\n",
            "  Class 0 (Severe Dysarthria        ):   4 ( 1.83%)\n",
            "  Class 1 (Moderate Dysarthria      ):  22 (10.05%)\n",
            "  Class 2 (Mild Dysarthria          ):  45 (20.55%)\n",
            "  Class 3 (No Dysarthria (ALS)      ):  62 (28.31%)\n",
            "  Class 4 (Healthy                  ):  86 (39.27%)\n",
            "\n",
            "âœ… Loaded 53 samples from: 'Validation Baseline - Task 1'\n",
            "ðŸ“Š Class distribution:\n",
            "  Class 0 (Severe Dysarthria        ):   2 ( 3.77%)\n",
            "  Class 1 (Moderate Dysarthria      ):   4 ( 7.55%)\n",
            "  Class 2 (Mild Dysarthria          ):  12 (22.64%)\n",
            "  Class 3 (No Dysarthria (ALS)      ):  14 (26.42%)\n",
            "  Class 4 (Healthy                  ):  21 (39.62%)\n",
            "\n",
            "ðŸ“ˆ Summary:\n",
            "  Training samples: 219\n",
            "  Validation samples: 53\n",
            "  Total audio files: 2176\n",
            "  Overlap check: âœ… No overlap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 5: LOAD WHISPER MODEL\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[2/9] LOADING WHISPER MODEL\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Model: {config.WHISPER_MODEL}\")\n",
        "print(\"â± This may take 1-2 minutes for first-time download...\")\n",
        "\n",
        "# Load feature extractor and model\n",
        "processor = WhisperProcessor.from_pretrained(config.WHISPER_MODEL)\n",
        "whisper_model = WhisperModel.from_pretrained(config.WHISPER_MODEL)\n",
        "whisper_model = whisper_model.to(device)\n",
        "whisper_model.eval()  # Set to evaluation mode\n",
        "\n",
        "print(f\"\\nâœ… Whisper loaded successfully!\")\n",
        "print(f\"  Model size: {sum(p.numel() for p in whisper_model.parameters()) / 1e6:.1f}M parameters\")\n",
        "print(f\"  Hidden size: {whisper_model.config.d_model}\")\n",
        "print(f\"  Number of encoder layers: {whisper_model.config.encoder_layers}\")\n",
        "print(f\"  Sampling rate: {processor.feature_extractor.sampling_rate} Hz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5NMyuFizN-Dx",
        "outputId": "1a2d79ba-bcdd-4cdd-aaae-7872065c9be8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[2/9] LOADING WHISPER MODEL\n",
            "================================================================================\n",
            "Model: openai/whisper-base\n",
            "â± This may take 1-2 minutes for first-time download...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Whisper loaded successfully!\n",
            "  Model size: 72.6M parameters\n",
            "  Hidden size: 512\n",
            "  Number of encoder layers: 6\n",
            "  Sampling rate: 16000 Hz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 6: ENHANCED AUDIO PROCESSING FUNCTIONS (NO PADDING VERSION)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[3/9] DEFINING ENHANCED AUDIO PROCESSING (NO PADDING)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def load_audio_enhanced(audio_path, target_sr=16000, max_length=None):\n",
        "    \"\"\"\n",
        "    Enhanced audio loading - EXTRACTS ONLY ACTUAL AUDIO CONTENT (NO PADDING)\n",
        "\n",
        "    Args:\n",
        "        audio_path: Path to audio file\n",
        "        target_sr: Target sampling rate\n",
        "        max_length: Maximum audio length in samples (will slice if longer)\n",
        "\n",
        "    Returns:\n",
        "        audio: Preprocessed audio waveform (actual content only)\n",
        "        sr: Sampling rate\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load audio\n",
        "        audio, sr = librosa.load(audio_path, sr=target_sr, mono=True)\n",
        "\n",
        "        # Advanced trimming with lower threshold for dysarthric speech\n",
        "        audio, _ = librosa.effects.trim(audio, top_db=config.AUDIO_TRIM_DB)\n",
        "\n",
        "        # Normalize amplitude\n",
        "        if config.AUDIO_NORMALIZE:\n",
        "            audio = librosa.util.normalize(audio)\n",
        "\n",
        "        # Slice to max_length instead of padding\n",
        "        if max_length and len(audio) > max_length:\n",
        "            audio = audio[:max_length]\n",
        "\n",
        "        # Only pad if audio is extremely short (< 2 seconds)\n",
        "        min_length = target_sr * config.MIN_AUDIO_LENGTH_SEC\n",
        "        if len(audio) < min_length:\n",
        "            # Pad only to minimum viable length (2 seconds)\n",
        "            audio = np.pad(audio, (0, min_length - len(audio)), mode='constant')\n",
        "\n",
        "        return audio, sr\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error loading {audio_path}: {str(e)}\")\n",
        "        # Return minimum silence as fallback\n",
        "        return np.zeros(target_sr * config.MIN_AUDIO_LENGTH_SEC), target_sr\n",
        "\n",
        "def extract_statistical_features(audio, sr=16000):\n",
        "    \"\"\"\n",
        "    Extract statistical and acoustic features from audio\n",
        "    These help capture dysarthria-specific patterns\n",
        "\n",
        "    Args:\n",
        "        audio: Audio waveform\n",
        "        sr: Sampling rate\n",
        "\n",
        "    Returns:\n",
        "        features: Array of statistical features\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # Time-domain statistics\n",
        "    features.extend([\n",
        "        np.mean(audio),           # Mean amplitude\n",
        "        np.std(audio),            # Standard deviation\n",
        "        skew(audio),              # Skewness\n",
        "        kurtosis(audio),          # Kurtosis\n",
        "        np.max(np.abs(audio)),    # Peak amplitude\n",
        "        np.median(audio),         # Median\n",
        "        np.percentile(audio, 25), # 25th percentile\n",
        "        np.percentile(audio, 75)  # 75th percentile\n",
        "    ])\n",
        "\n",
        "    # Zero crossing rate (voice quality indicator)\n",
        "    zcr = librosa.feature.zero_crossing_rate(audio)[0]\n",
        "    features.extend([np.mean(zcr), np.std(zcr), np.max(zcr)])\n",
        "\n",
        "    # Energy features\n",
        "    energy = np.sum(audio**2) / len(audio)\n",
        "    features.append(energy)\n",
        "\n",
        "    # RMS energy\n",
        "    rms = librosa.feature.rms(y=audio)[0]\n",
        "    features.extend([np.mean(rms), np.std(rms)])\n",
        "\n",
        "    # Spectral features\n",
        "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    features.extend([np.mean(spectral_centroids), np.std(spectral_centroids)])\n",
        "\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    features.extend([np.mean(spectral_rolloff), np.std(spectral_rolloff)])\n",
        "\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    features.extend([np.mean(spectral_bandwidth), np.std(spectral_bandwidth)])\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "def extract_whisper_features_multilayer(audio, sampling_rate=16000):\n",
        "    \"\"\"\n",
        "    Extract Whisper features with multi-layer and multi-pooling strategy\n",
        "    Handles variable-length audio without padding\n",
        "\n",
        "    Args:\n",
        "        audio: Audio waveform (actual content only, no padding)\n",
        "        sampling_rate: Sampling rate\n",
        "\n",
        "    Returns:\n",
        "        features: Concatenated feature vector\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Preprocess audio for Whisper\n",
        "        inputs = processor(\n",
        "            audio,\n",
        "            sampling_rate=sampling_rate,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Move to device\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Extract features with all hidden states\n",
        "        with torch.no_grad():\n",
        "            outputs = whisper_model.encoder(**inputs, output_hidden_states=True)\n",
        "\n",
        "        all_features = []\n",
        "\n",
        "        # Extract from multiple layers\n",
        "        if config.USE_MULTI_LAYER:\n",
        "            layers_to_process = config.LAYERS_TO_USE\n",
        "        else:\n",
        "            layers_to_process = [-1]  # Only last layer\n",
        "\n",
        "        for layer_idx in layers_to_process:\n",
        "            hidden_state = outputs.hidden_states[layer_idx]  # Shape: [batch, time, hidden]\n",
        "\n",
        "            # Apply multiple pooling strategies\n",
        "            if config.USE_MULTI_POOLING:\n",
        "                pooling_methods = config.POOLING_STRATEGIES\n",
        "            else:\n",
        "                pooling_methods = ['mean']  # Only mean pooling\n",
        "\n",
        "            for pool_strategy in pooling_methods:\n",
        "                if pool_strategy == 'mean':\n",
        "                    pooled = hidden_state.mean(dim=1)\n",
        "                elif pool_strategy == 'max':\n",
        "                    pooled = hidden_state.max(dim=1)[0]\n",
        "                elif pool_strategy == 'std':\n",
        "                    pooled = hidden_state.std(dim=1)\n",
        "                elif pool_strategy == 'min':\n",
        "                    pooled = hidden_state.min(dim=1)[0]\n",
        "                else:\n",
        "                    pooled = hidden_state.mean(dim=1)\n",
        "\n",
        "                all_features.append(pooled.cpu().numpy().squeeze())\n",
        "\n",
        "        # Concatenate all features\n",
        "        combined_features = np.concatenate(all_features)\n",
        "\n",
        "        return combined_features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Feature extraction error: {str(e)}\")\n",
        "        # Return zero features as fallback\n",
        "        n_layers = len(config.LAYERS_TO_USE) if config.USE_MULTI_LAYER else 1\n",
        "        n_pooling = len(config.POOLING_STRATEGIES) if config.USE_MULTI_POOLING else 1\n",
        "        feature_dim = whisper_model.config.d_model * n_layers * n_pooling\n",
        "        return np.zeros(feature_dim)\n",
        "\n",
        "print(\"âœ… Audio processing functions defined!\")\n",
        "print(f\"  Enhanced audio loading (NO PADDING): âœ“\")\n",
        "print(f\"  Statistical features ({20} features): âœ“\")\n",
        "print(f\"  Multi-layer Whisper extraction: âœ“\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Eca9x68CODlN",
        "outputId": "ec60f632-d1fc-4d93-de8a-3047ea0ef04c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[3/9] DEFINING ENHANCED AUDIO PROCESSING (NO PADDING)\n",
            "================================================================================\n",
            "âœ… Audio processing functions defined!\n",
            "  Enhanced audio loading (NO PADDING): âœ“\n",
            "  Statistical features (20 features): âœ“\n",
            "  Multi-layer Whisper extraction: âœ“\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 7: EXTRACT FEATURES FROM ALL AUDIO FILES (NO PADDING VERSION)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[4/9] EXTRACTING FEATURES (NO PADDING - ACTUAL AUDIO ONLY)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Layers: {len(config.LAYERS_TO_USE)}\")\n",
        "print(f\"  Pooling strategies: {len(config.POOLING_STRATEGIES)}\")\n",
        "print(f\"  Statistical features: {config.USE_STATISTICAL_FEATURES}\")\n",
        "print(f\"  Feature multiplication factor: {len(config.LAYERS_TO_USE) * len(config.POOLING_STRATEGIES)}x\")\n",
        "print(f\"  Max audio length: {config.MAX_AUDIO_LENGTH_SEC}s (NO PADDING BEYOND ACTUAL CONTENT)\")\n",
        "\n",
        "def extract_features_for_dataset(df, dataset_path, audio_types, desc=\"Processing\"):\n",
        "    \"\"\"\n",
        "    Extract enhanced features for entire dataset\n",
        "    Processes only actual audio content without padding\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with patient IDs and labels\n",
        "        dataset_path: Path to audio files\n",
        "        audio_types: List of audio types\n",
        "        desc: Progress bar description\n",
        "\n",
        "    Returns:\n",
        "        X: Feature matrix\n",
        "        y: Labels\n",
        "        ids: Patient IDs\n",
        "    \"\"\"\n",
        "    features_list = []\n",
        "    labels_list = []\n",
        "    ids_list = []\n",
        "\n",
        "    print(f\"\\nðŸŽµ {desc} {len(df)} patients...\")\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=desc):\n",
        "        patient_id = row['ID']\n",
        "        patient_class = row['Class']\n",
        "\n",
        "        patient_features = []\n",
        "\n",
        "        # Process each audio type\n",
        "        for audio_type in audio_types:\n",
        "            audio_file = f\"{patient_id}_{audio_type}.wav\"\n",
        "            audio_path = os.path.join(dataset_path, audio_type, audio_file)\n",
        "\n",
        "            if os.path.exists(audio_path):\n",
        "                # Load audio with NO padding (actual content only)\n",
        "                audio, sr = load_audio_enhanced(\n",
        "                    audio_path,\n",
        "                    target_sr=config.SAMPLING_RATE,\n",
        "                    max_length=config.MAX_AUDIO_LENGTH\n",
        "                )\n",
        "\n",
        "                # Extract Whisper features from actual audio\n",
        "                whisper_features = extract_whisper_features_multilayer(audio, sr)\n",
        "\n",
        "                # Extract statistical features if enabled\n",
        "                if config.USE_STATISTICAL_FEATURES:\n",
        "                    stat_features = extract_statistical_features(audio, sr)\n",
        "                    combined_features = np.concatenate([whisper_features, stat_features])\n",
        "                else:\n",
        "                    combined_features = whisper_features\n",
        "\n",
        "                patient_features.append(combined_features)\n",
        "            else:\n",
        "                # Zero features for missing files\n",
        "                n_layers = len(config.LAYERS_TO_USE) if config.USE_MULTI_LAYER else 1\n",
        "                n_pooling = len(config.POOLING_STRATEGIES) if config.USE_MULTI_POOLING else 1\n",
        "                feature_dim = whisper_model.config.d_model * n_layers * n_pooling\n",
        "\n",
        "                if config.USE_STATISTICAL_FEATURES:\n",
        "                    feature_dim += 20  # Statistical features count\n",
        "\n",
        "                patient_features.append(np.zeros(feature_dim))\n",
        "\n",
        "        # Concatenate features from all audio types\n",
        "        combined = np.concatenate(patient_features)\n",
        "        features_list.append(combined)\n",
        "        labels_list.append(patient_class)\n",
        "        ids_list.append(patient_id)\n",
        "\n",
        "    X = np.array(features_list)\n",
        "    y = np.array(labels_list)\n",
        "    ids = np.array(ids_list)\n",
        "\n",
        "    return X, y, ids\n",
        "\n",
        "# Extract training features\n",
        "X_train, y_train, ids_train = extract_features_for_dataset(\n",
        "    df_train,\n",
        "    config.TRAINING_PATH,\n",
        "    config.AUDIO_TYPES,\n",
        "    desc=\"Training\"\n",
        ")\n",
        "\n",
        "# Extract validation features\n",
        "X_val, y_val, ids_val = extract_features_for_dataset(\n",
        "    df_val,\n",
        "    config.TRAINING_PATH,\n",
        "    config.AUDIO_TYPES,\n",
        "    desc=\"Validation\"\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Feature extraction complete!\")\n",
        "print(f\"  Training shape: {X_train.shape}\")\n",
        "print(f\"  Validation shape: {X_val.shape}\")\n",
        "print(f\"  Feature dimension per patient: {X_train.shape[1]}\")\n",
        "\n",
        "# Clean data (handle any NaN/Inf)\n",
        "X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_val = np.nan_to_num(X_val, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "print(f\"  Data cleaned: âœ“\")\n",
        "\n",
        "# Save raw features\n",
        "features_path = os.path.join(config.OUTPUT_PATH, 'features_raw_no_padding_unbalanced.npz')\n",
        "np.savez(\n",
        "    features_path,\n",
        "    X_train=X_train, y_train=y_train, ids_train=ids_train,\n",
        "    X_val=X_val, y_val=y_val, ids_val=ids_val\n",
        ")\n",
        "print(f\"  ðŸ’¾ Raw features saved: {features_path}\")\n",
        "\n",
        "# Clear GPU memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "be4ac9cd31034e8eb733744e0fcf86e7",
            "a2955e22f9114f6b85b41c054cb68320",
            "e3027e3603184c46b30e23e76dff7e96",
            "379a6f2bbc9248629ff8145a75e1281e",
            "80424fe3c4174143854eb9b13c4e8539",
            "46a5b1b8163c4d78ad2b91cc1dbd765f",
            "71c1243c417f43a695c154d1069c5a5f",
            "d7dace37dacc4abca0e2158855dd356a",
            "77d7c8be493642fc85be434919d13ffb",
            "176c8618ea7b42dcb934199393eb9198",
            "212979d2b2d3412489980575df21f204",
            "7f024775ab244ea0bf825defb8881760",
            "7fcf66ffc588411abadb8748a1244f77",
            "799173b2973a4779a8d76db34ce2fdc9",
            "2fa54e8b46554b2aaf9e74a8232c6977",
            "c47a5023f9fa4284beed9283f9ed1ede",
            "db63e7946c314d65ab076c6c6a845428",
            "ee757cf26a3346bf89808f49854423c1",
            "21eaceefdd1f4c59a9fa7b0e4c64d54e",
            "66cdd14f1ebb45de90d7fcafe5cd90db",
            "3d78cf98c6ad4c6a88b2e1bf54b1d13c",
            "c9ee17683380420bad517ce8a0a22f22"
          ]
        },
        "id": "w_NDaHmEOHsN",
        "outputId": "0bf491f6-4d70-4bf8-f76a-df5f06070274"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[4/9] EXTRACTING FEATURES (NO PADDING - ACTUAL AUDIO ONLY)\n",
            "================================================================================\n",
            "Configuration:\n",
            "  Layers: 4\n",
            "  Pooling strategies: 4\n",
            "  Statistical features: True\n",
            "  Feature multiplication factor: 16x\n",
            "  Max audio length: 17s (NO PADDING BEYOND ACTUAL CONTENT)\n",
            "\n",
            "ðŸŽµ Training 219 patients...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/219 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be4ac9cd31034e8eb733744e0fcf86e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽµ Validation 53 patients...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation:   0%|          | 0/53 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f024775ab244ea0bf825defb8881760"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Feature extraction complete!\n",
            "  Training shape: (219, 65696)\n",
            "  Validation shape: (53, 65696)\n",
            "  Feature dimension per patient: 65696\n",
            "  Data cleaned: âœ“\n",
            "  ðŸ’¾ Raw features saved: /content/drive/MyDrive/SAND_Project_Data/optimized_whisper_rf_v2/features_raw_no_padding_unbalanced.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 8: ADVANCED PREPROCESSING PIPELINE (SMOTE COMMENTED OUT)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[5/9] ADVANCED PREPROCESSING (WITHOUT DATA BALANCING)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Step 1: Scaling\n",
        "if config.USE_ROBUST_SCALING:\n",
        "    print(\"ðŸ“Š Applying RobustScaler (better for outliers)...\")\n",
        "    scaler = RobustScaler()\n",
        "else:\n",
        "    print(\"ðŸ“Š Applying StandardScaler...\")\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "print(f\"  âœ… Scaling complete\")\n",
        "print(f\"     Train: mean={X_train_scaled.mean():.6f}, std={X_train_scaled.std():.6f}\")\n",
        "print(f\"     Val:   mean={X_val_scaled.mean():.6f}, std={X_val_scaled.std():.6f}\")\n",
        "\n",
        "# Step 2: PCA (Dimensionality Reduction)\n",
        "if config.USE_PCA:\n",
        "    print(f\"\\nðŸ“‰ Applying PCA (variance threshold={config.PCA_VARIANCE})...\")\n",
        "    pca = PCA(n_components=config.PCA_VARIANCE, random_state=config.RANDOM_SEED)\n",
        "    X_train_scaled = pca.fit_transform(X_train_scaled)\n",
        "    X_val_scaled = pca.transform(X_val_scaled)\n",
        "\n",
        "    explained_var = pca.explained_variance_ratio_.sum()\n",
        "    print(f\"  âœ… PCA complete\")\n",
        "    print(f\"     Original dimensions: {X_train.shape[1]}\")\n",
        "    print(f\"     Reduced dimensions: {X_train_scaled.shape[1]}\")\n",
        "    print(f\"     Explained variance: {explained_var*100:.2f}%\")\n",
        "    print(f\"     Dimensionality reduction: {X_train.shape[1]/X_train_scaled.shape[1]:.1f}x\")\n",
        "else:\n",
        "    pca = None\n",
        "    print(\"  â„¹ï¸ PCA disabled\")\n",
        "\n",
        "# Step 3: SMOTE (COMMENTED OUT - TESTING UNBALANCED DATA)\n",
        "# ============================================================================\n",
        "# COMMENTED OUT: Data balancing with SMOTE\n",
        "# ============================================================================\n",
        "# if config.USE_SMOTE:\n",
        "#     print(f\"\\nâš–ï¸ Applying SMOTE (strategy='{config.SMOTE_STRATEGY}')...\")\n",
        "#     print(f\"  Original class distribution:\")\n",
        "#     unique, counts = np.unique(y_train, return_counts=True)\n",
        "#     for cls, count in zip(unique, counts):\n",
        "#         print(f\"    Class {cls}: {count:3d}\")\n",
        "#\n",
        "#     try:\n",
        "#         smote = SMOTE(\n",
        "#             sampling_strategy=config.SMOTE_STRATEGY,\n",
        "#             k_neighbors=config.SMOTE_K_NEIGHBORS,\n",
        "#             random_state=config.RANDOM_SEED\n",
        "#         )\n",
        "#         X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "#\n",
        "#         print(f\"\\n  âœ… SMOTE complete\")\n",
        "#         print(f\"     Samples: {len(y_train)} â†’ {len(y_train_resampled)}\")\n",
        "#         print(f\"  Resampled class distribution:\")\n",
        "#         unique, counts = np.unique(y_train_resampled, return_counts=True)\n",
        "#         for cls, count in zip(unique, counts):\n",
        "#             print(f\"    Class {cls}: {count:3d}\")\n",
        "#\n",
        "#     except Exception as e:\n",
        "#         print(f\"  âš ï¸ SMOTE failed: {e}\")\n",
        "#         print(f\"  Continuing without SMOTE...\")\n",
        "#         X_train_resampled = X_train_scaled\n",
        "#         y_train_resampled = y_train\n",
        "# else:\n",
        "#     X_train_resampled = X_train_scaled\n",
        "#     y_train_resampled = y_train\n",
        "#     print(\"  â„¹ï¸ SMOTE disabled\")\n",
        "\n",
        "# Use original unbalanced data\n",
        "X_train_resampled = X_train_scaled\n",
        "y_train_resampled = y_train\n",
        "print(\"\\nâš ï¸ SMOTE DISABLED - Using original unbalanced data\")\n",
        "print(f\"  Training samples: {len(y_train_resampled)}\")\n",
        "print(f\"  Class distribution:\")\n",
        "unique, counts = np.unique(y_train_resampled, return_counts=True)\n",
        "for cls, count in zip(unique, counts):\n",
        "    print(f\"    Class {cls} ({config.CLASS_NAMES[cls]}): {count:3d}\")\n",
        "\n",
        "print(\"\\nâœ… Preprocessing pipeline complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2iEAEQhbOLNl",
        "outputId": "493a49f5-581d-4b97-8bc3-6b7d28fa0e24"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[5/9] ADVANCED PREPROCESSING (WITHOUT DATA BALANCING)\n",
            "================================================================================\n",
            "ðŸ“Š Applying RobustScaler (better for outliers)...\n",
            "  âœ… Scaling complete\n",
            "     Train: mean=0.008359, std=0.784949\n",
            "     Val:   mean=0.007654, std=0.856875\n",
            "\n",
            "ðŸ“‰ Applying PCA (variance threshold=0.97)...\n",
            "  âœ… PCA complete\n",
            "     Original dimensions: 65696\n",
            "     Reduced dimensions: 190\n",
            "     Explained variance: 97.00%\n",
            "     Dimensionality reduction: 345.8x\n",
            "\n",
            "âš ï¸ SMOTE DISABLED - Using original unbalanced data\n",
            "  Training samples: 219\n",
            "  Class distribution:\n",
            "    Class 0 (Severe Dysarthria):   4\n",
            "    Class 1 (Moderate Dysarthria):  22\n",
            "    Class 2 (Mild Dysarthria):  45\n",
            "    Class 3 (No Dysarthria (ALS)):  62\n",
            "    Class 4 (Healthy):  86\n",
            "\n",
            "âœ… Preprocessing pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 9: TRAIN OPTIMIZED RANDOM FOREST CLASSIFIER\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[6/9] TRAINING OPTIMIZED RANDOM FOREST\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Configuration:\")\n",
        "for key, value in config.RF_CONFIG.items():\n",
        "    if key != 'n_jobs':  # Don't print n_jobs as it's -1\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ Training Random Forest on {len(y_train_resampled)} samples (UNBALANCED DATA)...\")\n",
        "\n",
        "classifier = RandomForestClassifier(**config.RF_CONFIG)\n",
        "classifier.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "print(f\"âœ… Random Forest training complete!\")\n",
        "print(f\"  Number of trees: {classifier.n_estimators}\")\n",
        "print(f\"  Feature importance sum: {classifier.feature_importances_.sum():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SV54iA8JOWV5",
        "outputId": "7b90fcf3-19ab-40e4-8f05-93070756430f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[6/9] TRAINING OPTIMIZED RANDOM FOREST\n",
            "================================================================================\n",
            "Configuration:\n",
            "  n_estimators: 500\n",
            "  max_depth: 20\n",
            "  min_samples_split: 2\n",
            "  min_samples_leaf: 1\n",
            "  max_features: sqrt\n",
            "  bootstrap: True\n",
            "  class_weight: balanced\n",
            "  random_state: 42\n",
            "\n",
            "ðŸŽ¯ Training Random Forest on 219 samples (UNBALANCED DATA)...\n",
            "âœ… Random Forest training complete!\n",
            "  Number of trees: 500\n",
            "  Feature importance sum: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 10: CROSS-VALIDATION ON TRAINING SET\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[7/9] CROSS-VALIDATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Performing {config.N_FOLDS}-fold stratified cross-validation...\")\n",
        "print(\"â± This may take a few minutes...\")\n",
        "\n",
        "# Cross-validation on ORIGINAL training set (unbalanced)\n",
        "cv_classifier = RandomForestClassifier(**config.RF_CONFIG)\n",
        "cv_scores = cross_val_score(\n",
        "    cv_classifier,\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    cv=config.N_FOLDS,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Cross-validation complete!\")\n",
        "print(f\"  Fold scores: {[f'{s:.4f}' for s in cv_scores]}\")\n",
        "print(f\"  Mean CV F1: {cv_scores.mean():.4f}\")\n",
        "print(f\"  Std CV F1:  {cv_scores.std():.4f}\")\n",
        "print(f\"  Min CV F1:  {cv_scores.min():.4f}\")\n",
        "print(f\"  Max CV F1:  {cv_scores.max():.4f}\")\n",
        "\n",
        "# Detailed k-fold cross-validation metrics\n",
        "print(f\"\\nðŸ“Š DETAILED {config.N_FOLDS}-FOLD CROSS-VALIDATION METRICS:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Perform detailed cross-validation with multiple metrics\n",
        "kfold = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.RANDOM_SEED)\n",
        "\n",
        "cv_accuracy_scores = []\n",
        "cv_f1_cv_precision_scores = []\n",
        "cv_recall_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_scaled, y_train), 1):\n",
        "    X_fold_train, X_fold_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    # Train on fold\n",
        "    fold_classifier = RandomForestClassifier(**config.RF_CONFIG)\n",
        "    fold_classifier.fit(X_fold_train, y_fold_train)\n",
        "\n",
        "    # Predict on validation fold\n",
        "    y_fold_pred = fold_classifier.predict(X_fold_val)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_fold_val, y_fold_pred)\n",
        "    f1 = f1_score(y_fold_val, y_fold_pred, average='macro')\n",
        "    precision = precision_score(y_fold_val, y_fold_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_fold_val, y_fold_pred, average='macro', zero_division=0)\n",
        "\n",
        "    cv_accuracy_scores.append(accuracy)\n",
        "    cv_f1_scores.append(f1)\n",
        "    cv_precision_scores.append(precision)\n",
        "    cv_recall_scores.append(recall)\n",
        "\n",
        "    print(f\"Fold {fold}:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  F1 Score:  {f1:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  Samples:   Train={len(y_fold_train)}, Val={len(y_fold_val)}\")\n",
        "    print()\n",
        "\n",
        "print(\"ðŸ“ˆ CROSS-VALIDATION SUMMARY:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {np.mean(cv_accuracy_scores):.4f} Â± {np.std(cv_accuracy_scores):.4f}\")\n",
        "print(f\"F1 Score:  {np.mean(cv_f1_scores):.4f} Â± {np.std(cv_f1_scores):.4f}\")\n",
        "print(f\"Precision: {np.mean(cv_precision_scores):.4f} Â± {np.std(cv_precision_scores):.4f}\")\n",
        "print(f\"Recall:    {np.mean(cv_recall_scores):.4f} Â± {np.std(cv_recall_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1dCcy6P9PlxS",
        "outputId": "050b2d5d-ba5b-4b38-cf0d-f319e09d5a29"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[7/9] CROSS-VALIDATION\n",
            "================================================================================\n",
            "Performing 5-fold stratified cross-validation...\n",
            "â± This may take a few minutes...\n",
            "\n",
            "âœ… Cross-validation complete!\n",
            "  Fold scores: ['0.1115', '0.1133', '0.1115', '0.1637', '0.1417']\n",
            "  Mean CV F1: 0.1283\n",
            "  Std CV F1:  0.0211\n",
            "  Min CV F1:  0.1115\n",
            "  Max CV F1:  0.1637\n",
            "\n",
            "ðŸ“Š DETAILED 5-FOLD CROSS-VALIDATION METRICS:\n",
            "==================================================\n",
            "Fold 1:\n",
            "  Accuracy:  0.4091\n",
            "  F1 Score:  0.1161\n",
            "  Precision: 0.0818\n",
            "  Recall:    0.2000\n",
            "  Samples:   Train=175, Val=44\n",
            "\n",
            "Fold 2:\n",
            "  Accuracy:  0.3864\n",
            "  F1 Score:  0.1115\n",
            "  Precision: 0.0773\n",
            "  Recall:    0.2000\n",
            "  Samples:   Train=175, Val=44\n",
            "\n",
            "Fold 3:\n",
            "  Accuracy:  0.3864\n",
            "  F1 Score:  0.1115\n",
            "  Precision: 0.0773\n",
            "  Recall:    0.2000\n",
            "  Samples:   Train=175, Val=44\n",
            "\n",
            "Fold 4:\n",
            "  Accuracy:  0.3864\n",
            "  F1 Score:  0.1115\n",
            "  Precision: 0.0773\n",
            "  Recall:    0.2000\n",
            "  Samples:   Train=175, Val=44\n",
            "\n",
            "Fold 5:\n",
            "  Accuracy:  0.3721\n",
            "  F1 Score:  0.1404\n",
            "  Precision: 0.1000\n",
            "  Recall:    0.2353\n",
            "  Samples:   Train=176, Val=43\n",
            "\n",
            "ðŸ“ˆ CROSS-VALIDATION SUMMARY:\n",
            "==================================================\n",
            "Accuracy:  0.3881 Â± 0.0119\n",
            "F1 Score:  0.1182 Â± 0.0112\n",
            "Precision: 0.0827 Â± 0.0088\n",
            "Recall:    0.2071 Â± 0.0141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 11: EVALUATE ON TRAINING AND VALIDATION SETS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[8/9] MODEL EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# 1. TRAINING SET EVALUATION (Check for overfitting)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“Š TRAINING SET EVALUATION (Overfitting Check)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Predict on training set\n",
        "y_train_pred = classifier.predict(X_train_resampled)\n",
        "y_train_pred_proba = classifier.predict_proba(X_train_resampled)\n",
        "\n",
        "# Compute training metrics\n",
        "train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
        "train_f1_macro = f1_score(y_train_resampled, y_train_pred, average='macro')\n",
        "train_f1_weighted = f1_score(y_train_resampled, y_train_pred, average='weighted')\n",
        "train_precision = precision_score(y_train_resampled, y_train_pred, average='macro', zero_division=0)\n",
        "train_recall = recall_score(y_train_resampled, y_train_pred, average='macro', zero_division=0)\n",
        "train_kappa = cohen_kappa_score(y_train_resampled, y_train_pred)\n",
        "train_f1_per_class = f1_score(y_train_resampled, y_train_pred, average=None, zero_division=0)\n",
        "\n",
        "print(f\"Training Accuracy:      {train_accuracy:.4f}\")\n",
        "print(f\"Training F1 (Macro):    {train_f1_macro:.4f}\")\n",
        "print(f\"Training F1 (Weighted): {train_f1_weighted:.4f}\")\n",
        "print(f\"Training Precision:     {train_precision:.4f}\")\n",
        "print(f\"Training Recall:        {train_recall:.4f}\")\n",
        "print(f\"Training Kappa:         {train_kappa:.4f}\")\n",
        "\n",
        "# Training set classification report\n",
        "print(\"\\n\" + \"-\"*80)\n",
        "print(\"TRAINING CLASSIFICATION REPORT:\")\n",
        "print(\"-\"*80)\n",
        "available_classes_train = sorted(np.unique(y_train_resampled))\n",
        "class_labels_train = [config.CLASS_NAMES[i] for i in available_classes_train]\n",
        "print(classification_report(y_train_resampled, y_train_pred, target_names=class_labels_train, zero_division=0))\n",
        "\n",
        "# Training confusion matrix\n",
        "train_cm = confusion_matrix(y_train_resampled, y_train_pred)\n",
        "print(\"\\nTRAINING CONFUSION MATRIX:\")\n",
        "print(train_cm)\n",
        "\n",
        "# ============================================================================\n",
        "# 2. VALIDATION SET EVALUATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“Š VALIDATION SET EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Predict on validation set\n",
        "y_val_pred = classifier.predict(X_val_scaled)\n",
        "y_val_pred_proba = classifier.predict_proba(X_val_scaled)\n",
        "\n",
        "# Compute validation metrics\n",
        "accuracy = accuracy_score(y_val, y_val_pred)\n",
        "f1_macro = f1_score(y_val, y_val_pred, average='macro')\n",
        "f1_weighted = f1_score(y_val, y_val_pred, average='weighted')\n",
        "precision = precision_score(y_val, y_val_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_val, y_val_pred, average='macro', zero_division=0)\n",
        "kappa = cohen_kappa_score(y_val, y_val_pred)\n",
        "f1_per_class = f1_score(y_val, y_val_pred, average=None, zero_division=0)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽ¯ FINAL RESULTS - WHISPER + RANDOM FOREST (UNBALANCED DATA)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Validation Accuracy:      {accuracy:.4f}\")\n",
        "print(f\"F1 Score (Macro):         {f1_macro:.4f} âš ï¸ UNBALANCED DATA\")\n",
        "print(f\"F1 Score (Weighted):      {f1_weighted:.4f}\")\n",
        "print(f\"Precision (Macro):        {precision:.4f}\")\n",
        "print(f\"Recall (Macro):           {recall:.4f}\")\n",
        "print(f\"Cohen's Kappa:            {kappa:.4f}\")\n",
        "print(f\"CV F1 (Mean Â± Std):       {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# 3. OVERFITTING ANALYSIS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ” OVERFITTING ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate performance gaps\n",
        "accuracy_gap = train_accuracy - accuracy\n",
        "f1_gap = train_f1_macro - f1_macro\n",
        "precision_gap = train_precision - precision\n",
        "recall_gap = train_recall - recall\n",
        "\n",
        "print(f\"Performance Gaps (Training - Validation):\")\n",
        "print(f\"  Accuracy:  {train_accuracy:.4f} - {accuracy:.4f} = {accuracy_gap:+.4f}\")\n",
        "print(f\"  F1 Score:  {train_f1_macro:.4f} - {f1_macro:.4f} = {f1_gap:+.4f}\")\n",
        "print(f\"  Precision: {train_precision:.4f} - {precision:.4f} = {precision_gap:+.4f}\")\n",
        "print(f\"  Recall:    {train_recall:.4f} - {recall:.4f} = {recall_gap:+.4f}\")\n",
        "\n",
        "# Overfitting assessment\n",
        "if f1_gap > 0.15:\n",
        "    print(f\"\\nâš ï¸ SIGNIFICANT OVERFITTING DETECTED!\")\n",
        "    print(f\"   F1 gap: {f1_gap:.4f} > 0.15\")\n",
        "elif f1_gap > 0.10:\n",
        "    print(f\"\\nðŸ“ˆ MODERATE OVERFITTING DETECTED\")\n",
        "    print(f\"   F1 gap: {f1_gap:.4f} > 0.10\")\n",
        "elif f1_gap > 0.05:\n",
        "    print(f\"\\nðŸ“Š SLIGHT OVERFITTING DETECTED\")\n",
        "    print(f\"   F1 gap: {f1_gap:.4f} > 0.05\")\n",
        "else:\n",
        "    print(f\"\\nâœ… GOOD GENERALIZATION!\")\n",
        "    print(f\"   F1 gap: {f1_gap:.4f} â‰¤ 0.05\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. PER-CLASS PERFORMANCE (Validation)\n",
        "# ============================================================================\n",
        "print(\"\\nðŸ“Š PER-CLASS PERFORMANCE (Validation):\")\n",
        "available_classes = sorted(np.unique(y_val))\n",
        "for cls, f1_val in zip(available_classes, [f1_per_class[i] for i in available_classes]):\n",
        "    label = config.CLASS_NAMES[cls]\n",
        "    bar = 'â–ˆ' * int(f1_val * 40)\n",
        "    print(f\"  Class {cls} ({label:25s}): {f1_val:.4f} {bar}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n\" + \"-\"*80)\n",
        "print(\"CLASSIFICATION REPORT (Validation):\")\n",
        "print(\"-\"*80)\n",
        "class_labels = [config.CLASS_NAMES[i] for i in available_classes]\n",
        "print(classification_report(y_val, y_val_pred, target_names=class_labels, zero_division=0))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_val, y_val_pred)\n",
        "print(\"\\nCONFUSION MATRIX (Validation):\")\n",
        "print(cm)\n",
        "\n",
        "# ============================================================================\n",
        "# 5. ACHIEVEMENT STATUS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "baseline_f1 = 0.4919\n",
        "target_f1 = 0.70\n",
        "improvement = f1_macro - baseline_f1\n",
        "\n",
        "if f1_macro >= target_f1:\n",
        "    print(f\"ðŸŽ‰ðŸŽ‰ðŸŽ‰ TARGET ACHIEVED! ðŸŽ‰ðŸŽ‰ðŸŽ‰\")\n",
        "    print(f\"F1 Score: {f1_macro:.4f} >= {target_f1:.4f}\")\n",
        "    print(f\"Improvement over baseline: +{improvement:.4f} (+{improvement/baseline_f1*100:.1f}%)\")\n",
        "elif f1_macro >= 0.65:\n",
        "    print(f\"ðŸš€ EXCELLENT PROGRESS!\")\n",
        "    print(f\"F1 Score: {f1_macro:.4f}\")\n",
        "    print(f\"Gap to target: -{target_f1 - f1_macro:.4f}\")\n",
        "    print(f\"Improvement over baseline: +{improvement:.4f} (+{improvement/baseline_f1*100:.1f}%)\")\n",
        "else:\n",
        "    print(f\"ðŸ“ˆ TESTING UNBALANCED DATA\")\n",
        "    print(f\"F1 Score: {f1_macro:.4f}\")\n",
        "    print(f\"Improvement over baseline: {improvement:+.4f} ({improvement/baseline_f1*100:+.1f}%)\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "95U9C3giPyt_",
        "outputId": "a501cad9-b49b-4114-fabd-c5e3000f8135"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[8/9] MODEL EVALUATION\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š TRAINING SET EVALUATION (Overfitting Check)\n",
            "================================================================================\n",
            "Training Accuracy:      0.9954\n",
            "Training F1 (Macro):    0.9972\n",
            "Training F1 (Weighted): 0.9954\n",
            "Training Precision:     0.9968\n",
            "Training Recall:        0.9977\n",
            "Training Kappa:         0.9936\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "TRAINING CLASSIFICATION REPORT:\n",
            "--------------------------------------------------------------------------------\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  Severe Dysarthria       1.00      1.00      1.00         4\n",
            "Moderate Dysarthria       1.00      1.00      1.00        22\n",
            "    Mild Dysarthria       1.00      1.00      1.00        45\n",
            "No Dysarthria (ALS)       0.98      1.00      0.99        62\n",
            "            Healthy       1.00      0.99      0.99        86\n",
            "\n",
            "           accuracy                           1.00       219\n",
            "          macro avg       1.00      1.00      1.00       219\n",
            "       weighted avg       1.00      1.00      1.00       219\n",
            "\n",
            "\n",
            "TRAINING CONFUSION MATRIX:\n",
            "[[ 4  0  0  0  0]\n",
            " [ 0 22  0  0  0]\n",
            " [ 0  0 45  0  0]\n",
            " [ 0  0  0 62  0]\n",
            " [ 0  0  0  1 85]]\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š VALIDATION SET EVALUATION\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ¯ FINAL RESULTS - WHISPER + RANDOM FOREST (UNBALANCED DATA)\n",
            "================================================================================\n",
            "Validation Accuracy:      0.3774\n",
            "F1 Score (Macro):         0.1096 âš ï¸ UNBALANCED DATA\n",
            "F1 Score (Weighted):      0.2171\n",
            "Precision (Macro):        0.0769\n",
            "Recall (Macro):           0.1905\n",
            "Cohen's Kappa:            -0.0270\n",
            "CV F1 (Mean Â± Std):       0.1283 Â± 0.0211\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ” OVERFITTING ANALYSIS\n",
            "================================================================================\n",
            "Performance Gaps (Training - Validation):\n",
            "  Accuracy:  0.9954 - 0.3774 = +0.6181\n",
            "  F1 Score:  0.9972 - 0.1096 = +0.8876\n",
            "  Precision: 0.9968 - 0.0769 = +0.9199\n",
            "  Recall:    0.9977 - 0.1905 = +0.8072\n",
            "\n",
            "âš ï¸ SIGNIFICANT OVERFITTING DETECTED!\n",
            "   F1 gap: 0.8876 > 0.15\n",
            "\n",
            "ðŸ“Š PER-CLASS PERFORMANCE (Validation):\n",
            "  Class 0 (Severe Dysarthria        ): 0.0000 \n",
            "  Class 1 (Moderate Dysarthria      ): 0.0000 \n",
            "  Class 2 (Mild Dysarthria          ): 0.0000 \n",
            "  Class 3 (No Dysarthria (ALS)      ): 0.0000 \n",
            "  Class 4 (Healthy                  ): 0.5479 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "CLASSIFICATION REPORT (Validation):\n",
            "--------------------------------------------------------------------------------\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  Severe Dysarthria       0.00      0.00      0.00         2\n",
            "Moderate Dysarthria       0.00      0.00      0.00         4\n",
            "    Mild Dysarthria       0.00      0.00      0.00        12\n",
            "No Dysarthria (ALS)       0.00      0.00      0.00        14\n",
            "            Healthy       0.38      0.95      0.55        21\n",
            "\n",
            "           accuracy                           0.38        53\n",
            "          macro avg       0.08      0.19      0.11        53\n",
            "       weighted avg       0.15      0.38      0.22        53\n",
            "\n",
            "\n",
            "CONFUSION MATRIX (Validation):\n",
            "[[ 0  0  0  0  2]\n",
            " [ 0  0  0  0  4]\n",
            " [ 0  0  0  0 12]\n",
            " [ 0  0  0  0 14]\n",
            " [ 0  0  0  1 20]]\n",
            "\n",
            "================================================================================\n",
            "ðŸ“ˆ TESTING UNBALANCED DATA\n",
            "F1 Score: 0.1096\n",
            "Improvement over baseline: -0.3823 (-77.7%)\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 12: SAVE MODEL AND RESULTS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[9/9] SAVING MODEL AND RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save model\n",
        "model_path = os.path.join(config.OUTPUT_PATH, 'random_forest_model_unbalanced.joblib')\n",
        "joblib.dump(classifier, model_path)\n",
        "print(f\"âœ… Model saved: {model_path}\")\n",
        "\n",
        "# Save scaler\n",
        "scaler_path = os.path.join(config.OUTPUT_PATH, 'scaler_unbalanced.joblib')\n",
        "joblib.dump(scaler, scaler_path)\n",
        "print(f\"âœ… Scaler saved: {scaler_path}\")\n",
        "\n",
        "# Save PCA\n",
        "if pca is not None:\n",
        "    pca_path = os.path.join(config.OUTPUT_PATH, 'pca_unbalanced.joblib')\n",
        "    joblib.dump(pca, pca_path)\n",
        "    print(f\"âœ… PCA saved: {pca_path}\")\n",
        "\n",
        "# Save results\n",
        "results = {\n",
        "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'model': 'Random Forest',\n",
        "    'feature_extractor': 'Whisper (openai/whisper-base)',\n",
        "    'audio_processing': 'No padding - actual content only (max 17s)',\n",
        "    'data_balancing': 'DISABLED - Testing unbalanced data',\n",
        "    'validation_metrics': {\n",
        "        'accuracy': float(accuracy),\n",
        "        'f1_macro': float(f1_macro),\n",
        "        'f1_weighted': float(f1_weighted),\n",
        "        'precision': float(precision),\n",
        "        'recall': float(recall),\n",
        "        'kappa': float(kappa)\n",
        "    },\n",
        "    'cross_validation': {\n",
        "        'mean_f1': float(cv_scores.mean()),\n",
        "        'std_f1': float(cv_scores.std()),\n",
        "        'fold_scores': [float(s) for s in cv_scores]\n",
        "    },\n",
        "    'training_metrics': {\n",
        "        'accuracy': float(train_accuracy),\n",
        "        'f1_macro': float(train_f1_macro),\n",
        "        'precision': float(train_precision),\n",
        "        'recall': float(train_recall)\n",
        "    },\n",
        "    'overfitting_gaps': {\n",
        "        'accuracy_gap': float(accuracy_gap),\n",
        "        'f1_gap': float(f1_gap),\n",
        "        'precision_gap': float(precision_gap),\n",
        "        'recall_gap': float(recall_gap)\n",
        "    },\n",
        "    'per_class_f1': {config.CLASS_NAMES[i]: float(f1_per_class[i]) for i in available_classes},\n",
        "    'confusion_matrix': cm.tolist(),\n",
        "    'config': {\n",
        "        'max_audio_length_sec': config.MAX_AUDIO_LENGTH_SEC,\n",
        "        'use_padding': config.USE_PADDING,\n",
        "        'use_multi_layer': config.USE_MULTI_LAYER,\n",
        "        'use_multi_pooling': config.USE_MULTI_POOLING,\n",
        "        'use_statistical_features': config.USE_STATISTICAL_FEATURES,\n",
        "        'use_pca': config.USE_PCA,\n",
        "        'use_smote': config.USE_SMOTE,\n",
        "        'rf_n_estimators': config.RF_CONFIG['n_estimators']\n",
        "    }\n",
        "}\n",
        "\n",
        "results_path = os.path.join(config.OUTPUT_PATH, 'results_unbalanced.json')\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print(f\"âœ… Results saved: {results_path}\")\n",
        "\n",
        "# Save predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'ID': ids_val,\n",
        "    'True_Class': y_val,\n",
        "    'Predicted_Class': y_val_pred,\n",
        "    'True_Label': [config.CLASS_NAMES[c] for c in y_val],\n",
        "    'Predicted_Label': [config.CLASS_NAMES[c] for c in y_val_pred],\n",
        "    'Correct': y_val == y_val_pred\n",
        "})\n",
        "\n",
        "# Add prediction probabilities\n",
        "for i in range(len(config.CLASS_NAMES)):\n",
        "    predictions_df[f'Prob_Class_{i}'] = y_val_pred_proba[:, i]\n",
        "\n",
        "predictions_path = os.path.join(config.OUTPUT_PATH, 'validation_predictions_unbalanced.csv')\n",
        "predictions_df.to_csv(predictions_path, index=False)\n",
        "print(f\"âœ… Predictions saved: {predictions_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽŠ ALL TASKS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Validation F1 Score: {f1_macro:.4f} âš ï¸ UNBALANCED DATA\")\n",
        "print(f\"  Validation Accuracy: {accuracy:.4f}\")\n",
        "print(f\"  CV F1 Score: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
        "print(f\"  Overfitting (F1 gap): {f1_gap:.4f}\")\n",
        "print(f\"\\nAll outputs saved to: {config.OUTPUT_PATH}\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "2K56zn66P6hS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}